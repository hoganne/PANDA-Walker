# kafka常见问题总结

![img](https://images2015.cnblogs.com/blog/689056/201701/689056-20170109094851244-1661701432.jpg)

消息队列服务相信大家一定都不陌生了，在很多应用系统中，都有一些场景会使用到消息队列服务，简单来说，我们可以把消息队列比作是一个存放消息的容器，上游发送端将消息发送到消息队列，下游消费端从消息队列里消费消息。消息队列是分布式系统中重要的组件，核心作用可以帮助我们实现异步、解耦以及削峰，从而提高系统性能和稳定性。

在大部分场景下业务系统如果只需要实现异步解耦、削峰填谷等能力，常规的普通消息就可以满足此类需求。除此之外，在某些特殊的业务场景中，普通消息类型存在无法满足需求的情况。这就需要消息队列服务本身支持一些特殊的消息类型，或者开发者通过开发一些定制化的代码实现目的。这里我们列举在使用消息队列过程中几种特殊场景的例子：

### 顺序消费场景

生产者按照一定的先后顺序发布消息，消费者按照既定的先后顺序消费消息，即先发布的消息一定会先被客户端消费。

### 分布式事务场景

分布式架构下，随着系统的演进，数据库也进行了垂直拆分，如果选择使用消息队列进行上下游解耦的话，生产者和消费者需要保证数据一致性。

这篇说说分布式事务的问题。企业现在的架构都由传统的架构转向了微服务架构，如下图所示:
![img](https://img2018.cnblogs.com/blog/725429/201812/725429-20181213190141873-525805351.png)

那么，都不可避免的会遇到跨数据库调用的，分布式事务问题！
目前，业内解决分布式事务问题，都基本不用JTA这种强一致性的解决方案，基本是采用如下两套方案

- 基于`TCC`的事务框架

- 消息队列
  (1) 图中的服务A和服务B，如果是同步调用，要求一起成功，或者一起失败，那么此时应选用`TCC`的事务框架，这点我改天另写一篇，先挖坑！
  (2) 图中的服务A和服务B，如果是异步调用，比如服务C先调用服务A后，服务C不用管服务B的执行结果，直接返回，那么这种情况下，应选用消息队列！这篇文章重点讲！
  目前为止，大部分文章都讲的太复杂了。导致很多新人看完后于是看这篇文章前，你们先忘记你们在其他文章看到的概念，跟着博主的思路走！

- 先给大家套一个业务场景，也是很常见的一个异步调用场景:

  - 支付宝往余额宝转钱

  即将服务A假设为支付宝，服务B假设为余额宝。
  于是呢，我们的支付宝往余额宝转100块钱是怎么做的呢？
  特别容易，借助消息队列即可，如下图所示
  ![img](https://img2018.cnblogs.com/blog/725429/201812/725429-20181213190213053-1314882239.png)

  ### 一致性解决

  OK，上面这一版有一个致命的问题！如下所示
  *事务开始
  (1)给支付宝账户zhangsan,扣100元
  (2)将(给余额宝账户zhangsan,加100元)封装为消息，发送给消息队列
  事务结束*
  敢问你，如何保证第一步和第二步是在同一个事务里完成的。换句话说，第一步操作的是数据库，第二步操作的是一个消息队列，你如何保证这两步之间的一致性？
  记住了，任何涉及到数据库和中间件之间的业务逻辑操作，都需要考虑二者之间的一致性。比如，你先操作了数据库，再操作缓存，数据库和缓存之间一致性如何解决？好吧，如果是博主的铁粉，应该知道怎么解决了，回到我们的场景。
  改变思路，加一张事务表，如下图所示
  ![img](https://img2018.cnblogs.com/blog/725429/201812/725429-20181213190227021-1756099849.png)

  注意了，此时事务的内容为
  *事务开始
  (1)给支付宝账户zhangsan,扣100元
  (2)给事件表插入一条记录
  事务结束*
  此时是对同一数据库的两张表操作，因此可以用数据库的事务进行保证。
  另外，起一个定时程序，定时扫描事务表，发现一个状态为'UNFINISHED'的事件，就进行封装为消息，发送到消息中间件，然后将状态改为'FINISHED'.

  ### 幂等性解决

  注意了，这一版还存在一个幂等性问题!
  仔细看，定时程序做了如下三个操作
  (1)定时扫描事务表，发现一个状态为'UNFINISHED'的事件
  (2)将事件信息，封装为消息，发送到消息中间件
  (3)将事件状态改为'FINISHED'

  OK，假设在步骤(2)的时候，发送完消息体，还未执行步骤(3),定时程序阵亡了！然后重启定时程序，发现刚那个事务的状态依然为'UNFINISHED'，因此重新发送。这样，就会出现重复消费问题。因此，幂等性也是需要保证的！

  如果是博主的忠实读者，应该知道，博主曾经写过一篇[《分布式之消息队列复习精讲》](https://www.cnblogs.com/rjzheng/p/8994962.html)，里头就提到了如何解决幂等性问题。
  借用这篇文章里的方案。在消费者端，也维护一个带主键的表，可以选txid为主键，如下图所示
  ![img](https://img2018.cnblogs.com/blog/725429/201812/725429-20181213190243278-1105873311.png)

  如果一旦出现重复消费，则在事务里直接报出主键冲突错误，从而保证了幂等性！

### 延时消费场景

​		生产者将消息发送到消息队列后，并不期望立马投递这条消息，而是推迟到某个时间点之后将消息投递给消费者进行消费。

​		对于顺序消息和事务消息，这里就不进行详细介绍了，大家有兴趣可以自行研究，本文后续内容会和大家一起详细讨论下延时消息更多的细节及应用场景。

## 延时消息介绍

​		延时(定时)消息的特点就是发送者成功发送一条消息后，这条消息并不会马上被消费者消费，而是在某个特定的时间或者延迟一段时间后，消息才被消费者可见并进行后续的消费，延时消息整个生命周期可以用如下示意图来表示：





![img](https://pic2.zhimg.com/v2-211469fcf2f64a2b6ebdf940fec7f79d_b.jpg)



1. 消息发布者将一条延时消息发送到消息队列服务端；

2. 在预计投递时间未到之前，消息对消费者不可见，消费者此时无法立刻消费；

3. 投递时间到达后，消息才对消费者可见，消费者此时可以消费；

4. 消费者获取此条消息并进行消费；

5. 消费者成功消费后，进行确认，此条消息将不再被消费。

   ## 延时消息应用场景

   ### 交易场景

   在生产者和消费者有时间窗口的要求下，我们可以考虑使用延时消息。如在电商交易场景下，交易中超时未支付的订单需要被关闭的场景，在订单创建时会发送一条延时消息。这条消息将会在30分钟以后投递给消费者，消费者收到此消息后，需要判断对应的订单是否已完成支付；如支付未完成，则关闭订单。

   

   

   ![img](https://pic2.zhimg.com/v2-72ba3d48d2a8b96d57345e884f722811_b.jpg)

   

   ### 游戏场景

   再比如在游戏社区里，游戏运营方经常会发起一些活动，玩家在活动期间内按照规则完成一系列任务，活动时间截止后，游戏后台根据玩家完成任务的情况进行判定，发送系统通知或者进行rank排名并派发奖励等。

   

   

   ![img](https://pic3.zhimg.com/v2-4f807dcb1b5652357c63cb2b54b0766a_b.jpg)

   

   此种场景也可以采用延时消息来实现，上游系统发布活动公告后，同时发送一条延时消息，延时时间设置为活动周期的时间。当活动截止后，下游系统可以随即消费消息并进行相应的逻辑处理。

   ### 其他场景

   同时延时消息也可以广泛应用于信息提醒等比较通用的场景。

   ## 如何实现延时消息

   介绍完延时消息的一些概念及应用场景后，我们接下来分析一下目前比较主流的几款开源消息中间件对延时消息的支持情况以及实现方式。

   ### Kafka

   原生Kafka默认是不支持延时消息的，需要开发者自己实现一层代理服务，比如发送端将消息发送到延时Topic，代理服务消费延时Topic的消息然后转存起来，代理服务通过一定的算法，计算延时消息所附带的延时时间是否到达，然后将延时消息取出来并发送到实际的Topic里面，消费端从实际的Topic里面进行消费。

   ### RabbitMQ

   RabbitMQ实现延时消息有两种方案，

   第一种是采用rabbitmq-delayed-message-exchange 插件实现，

   第二种则是利用DLX（Dead Letter Exchanges）+ TTL（消息存活时间）来间接实现。大致的实现思路如下：

   1. 创建一个普通队列delay_queue，为此队列设置死信交换机 (通过x-dead-letter-exchange参数) 和 RoutingKey (通过x-dead-letter-routing-key参数)，生产者将向delay_queue发送延时消息。
   2. 创建步骤1中设置的死信交换机，同时创建一个目标队列 target_queue，并使用步骤1中设置的RoutingKey将两者绑定起来。消费者将从target_queue里面消费延时消息。
   3. 设置消息的存活时间TTL，可以在步骤1中设置到队列级别delay_queue的消息存活时间，或者在发送消息时动态设置消息级别的存活时间。

   ### RocketMQ

   开源RocketMQ支持延迟消息，但是不支持秒级精度。默认支持18个level的延迟消息，这是通过broker端的messageDelayLevel配置项确定的
   `messageDelayLevel=1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h`

   消息队列服务在启动时，会创建一个内部topic：SCHEDULE_TOPIC_XXXX，根据延迟level的个数，创建对应数量的队列。生产者发送消息时可以设置延时等级，示例代码:

   ```text
   Message msg=new Message();
   msg.setTopic("TopicA");
   msg.setBody("this is a delay message".getBytes());
   //设置延迟level为5，对应延迟1分钟
   msg.setDelayTimeLevel(5);
   producer.send(msg);
   ```

   发送的消息会暂存在Broker对应的内部topic中，再通过定时任务从内部topic中拉取数据，如果延迟时间到了，就会把消息转发到目标topic下，消费者从目标topic消费消息。

   ## 阿里云消息队列RocketMQ版

   通过上一章节的讨论，我们可以看出目前几款主流的开源消息队列服务，在支持延时消息的场景下或多或少有些不完美的地方。主要体现在以下几点:

   1. Kafka不支持延时消息，需要完全开发代理服务来实现，工作量大。
   2. RabbitMQ需要额外的插件，或者利用DLX+TTL的方式进行中转，实现不是非常直观。
   3. RocketMQ支持延时消息，但是无法支持秒级延时。

   那么有没有一款消息队列服务，能够完美的支持延时（定时）消息。本节我们将介绍阿里云消息队列RocketMQ版。

   阿里云消息队列RocketMQ版基于Apache RocketMQ构建的低延迟、高并发、高可用、高可靠的分布式消息中间件。消息队列RocketMQ版既可为分布式应用系统提供异步解耦和削峰填谷的能力，同时也具备互联网应用所需的海量消息堆积、高吞吐、可靠重试等特性。同时支持丰富的消息类型包括普通消息、顺序消息、事务消息以及我们本文讨论的延时消息。接下来我们看下阿里云RocketMQ为延时消息提供的能力及优势：

   1. 支持秒级的延时(定时)消息，同时延时时间可以最大设置为40天，基本满足所有场景。
   2. 延时(定时)消息的投递精度可控制在1~2秒之内。
   3. 延时(定时)消息在某段时间内是对消费者不可见的，从另一个维度看也属于积压的消息，阿里云消息队列RocketMQ版的不同实例规格可以支持亿级的消息积压。
   4. 提供了多语言支持，包括Java、.NET、CC++、GO、Python、PHP、Node.js等

   使用阿里云消息队列RocketMQ版收发延时(定时)消息，只需要在控制台创建Topic的时候选择定时/延时消息类型，既可以使用TCP或者http协议进行消息收发。

   ### 控制台创建定时/延时Topic

   

   

   ![img](https://pic3.zhimg.com/v2-9111a48f9adbb466b3debfa48a641fc6_b.jpg)

   

   ### Java语言示例代码（TCP协议）

   - **发送定时消息**

   ```text
   // 定时消息，单位毫秒（ms），在指定时间戳（当前时间之后）进行投递，例如2020-03-07 16:21:00投递。如果被设置成当前时间戳之前的某个时刻，消息将立刻投递给消费者。
   long timeStamp = new SimpleDateFormat("yyyy-MM-dd HH:mm:ss").parse("2020-03-07 16:21:00").getTime();
   msg.setStartDeliverTime(timeStamp);
   // 发送消息，只要不抛异常就是成功。
   SendResult sendResult = producer.send(msg);
   ```

   - **发送延时消息**

   ```text
   // 延时消息，单位毫秒（ms），在指定延迟时间（当前时间之后）进行投递，例如消息在3秒后投递。
   long delayTime = System.currentTimeMillis() + 3000;
   // 设置消息需要被投递的时间。
   msg.setStartDeliverTime(delayTime);
   SendResult sendResult = producer.send(msg);
   ```

   同时订阅延时消息的逻辑无需任何改造，完全可以按照订阅普通消息的方式，没有任何的代码侵入性。

   ## 结束语

   到此我们讨论了延时消息的特性、应用场景，对比了各类消息队列对延时消息的支持情况，同时也向大家介绍了阿里云消息队列RocketMQ版。我们在对消息中间件进行选型时，也会考虑到多方面的因素。除了消息中间件本身所能提供的能力外，也包括服务性能、稳定性、可扩展能力，以及需要结合开发团队自身的技术栈等情况。最后如果大家想了解更多阿里云消息队列RocketMQ版。

   

## （kafka）出现后有如下好处:

### **1、 解耦**（生产者和消费者之间可以不用各自等待对方）

快递小哥手上有很多快递需要送，他每次都需要先电话一一确认收货人是否有空、哪个时间段有空，然后再确定好送货的方案。这样完全依赖收货人了！如果快递一多，快递小哥估计的忙疯了……如果有了便利店，快递小哥只需要将同一个小区的快递放在同一个便利店，然后通知收货人来取货就可以了，这时候快递小哥和收货人就实现了解耦！

### **2、 异步**（生产者、消费者可以异步生产消费）

快递小哥打电话给我后需要一直在你楼下等着，直到我拿走你的快递他才能去送其他人的。快递小哥将快递放在小芳便利店后，又可以干其他的活儿去了，不需要等待你到来而一直处于等待状态。提高了工作的效率。

### **3、 削峰**

假设双十一我买了不同店里的各种商品，而恰巧这些店发货的快递都不一样，有中通、圆通、申通、各种通等……更巧的是他们都同时到货了！中通的小哥打来电话叫我去北门取快递、圆通小哥叫我去南门、申通小哥叫我去东门。我一时手忙脚乱……

我们能看到在系统需要交互的场景中，使用消息队列中间件真的是好处多多，基于这种思路，就有了丰巢、菜鸟驿站等比便利店更专业的“中间件”了。

## **消息队列通信的模式**

通过上面的例子我们引出了消息中间件，并且介绍了消息队列出现后的好处，这里就需要介绍消息队列通信的两种模式了：

### **一、 点对点模式**

![img](https://pic3.zhimg.com/v2-8ca010d65aa8e4c385a901fb2e91f31a_b.jpg)

如上图所示，点对点模式通常是基于拉取或者轮询的消息传送模型，这个模型的特点是发送到队列的消息被一个且只有一个消费者进行处理。生产者将消息放入消息队列后，由消费者主动的去拉取消息进行消费。点对点模型的的优点是消费者拉取消息的频率可以由自己控制。但是消息队列是否有消息需要消费，在消费者端无法感知，所以在消费者端需要额外的线程去监控。

### **二、 发布订阅模式**

![img](https://pic4.zhimg.com/v2-92c5c49e68a6213914936ed979c05c6b_b.jpg)

如上图所示，发布订阅模式是一个基于消息推送的消息传送模型，该模型可以有多种不同的订阅者。生产者将消息放入消息队列后，队列会将消息推送给订阅过该类消息的消费者（类似微信公众号）。由于是消费者被动接收推送，所以无需感知消息队列是否有待消费的消息！但是consumer1、consumer2、consumer3由于机器性能不一样，所以处理消息的能力也会不一样，但消息队列却无法感知消费者消费的速度！所以推送的速度成了发布订阅模模式的一个问题！假设三个消费者处理速度分别是8M/s、5M/s、2M/s，如果队列推送的速度为5M/s，则consumer3无法承受！如果队列推送的速度为2M/s，则consumer1、consumer2会出现资源的极大浪费！

## **Kafka**

上面简单的介绍了为什么需要消息队列以及消息队列通信的两种模式！Kafka是一种高吞吐量的分布式发布订阅消息系统，它可以处理消费者规模的网站中的所有动作流数据，具有高性能、持久化、多副本备份、横向扩展能力……… 一些基本的介绍这里就不展开了，网上有太多关于这些的介绍了，读者可以自行百度一下！

### **基础架构及术语**

话不多说，先看图，通过这张图我们来捋一捋相关的概念及之间的关系：

![img](https://pic1.zhimg.com/v2-4692429e9184ed4a93911fa3a1361d28_b.jpg)

我们先来分析相关概念

**Producer**：Producer即生产者，消息的产生者，是消息的入口。

**kafka cluster**：

**Broker**：Broker是kafka实例，每个服务器上有一个或多个`kafka`的实例，我们姑且认为每个broker对应一台服务器。每个`kafka`集群内的broker都有一个**不重复**的编号，如图中的`broker-0`、`broker-1`等……

**Topic**：消息的主题，可以理解为消息的分类，`kafka`的数据就保存在topic。在每个`broker`上都可以创建多个`topic`。

**Partition**：Topic的分区，每个topic可以有多个分区，分区的作用是做负载，提高kafka的吞吐量。同一个topic在不同的分区的数据是不重复的，partition的表现形式就是一个一个的文件夹！

**Replication**:每一个分区都有多个副本，副本的作用是做备胎。当主分区（Leader）故障的时候会选择一个备胎（Follower）上位，成为Leader。在kafka中默认副本的最大数量是10个，且副本的数量不能大于Broker的数量，follower和leader绝对是在不同的机器，同一机器对同一个分区也只可能存放一个副本（包括自己）。

**Message**：每一条发送的消息主体。

**Consumer**：消费者，即消息的消费方，是消息的出口。

**Consumer Group**：我们可以将多个消费者组成一个消费者组，在kafka的设计中同一个分区的数据只能被消费者组中的某一个消费者消费。同一个消费者组的消费者可以消费同一个topic的不同分区的数据，这也是为了提高kafka的吞吐量！

**Zookeeper**：kafka集群依赖zookeeper来保存集群的的元信息，来保证系统的可用性。

### **工作流程分析**

我们接下来再结合上面的结构图分析kafka的工作流程，最后再回来整个梳理一遍我相信你会更有收获！

#### **发送数据**

我们看上面的架构图中，producer就是生产者，是数据的入口。注意看图中的红色箭头，Producer在写入数据的时候**永远的找leader**，不会直接将数据写入follower！那leader怎么找呢？写入的流程又是什么样的呢？我们看下图：

![img](https://pic2.zhimg.com/v2-b7e72e9c5b9971e89ec174a2c2201ed9_b.jpg)

发送的流程就在图中已经说明了，就不单独在文字列出来了！需要注意的一点是，消息写入leader后，follower是主动的去leader进行同步的！producer采用push模式将数据发布到broker，每条消息追加到分区中，顺序写入磁盘，所以保证**同一分区**内的数据是有序的！写入示意图如下：

![img](https://pic3.zhimg.com/v2-87d558aaa349bf920711b9c157e11f6a_b.jpg)

上面说到数据会写入到不同的分区，那kafka为什么要做分区呢？相信大家应该也能猜到，分区的主要目的是：

**1、 方便扩展**。因为一个topic可以有多个partition，所以我们可以通过扩展机器去轻松的应对日益增长的数据量。

**2、 提高并发**。以partition为读写单位，可以多个消费者同时消费数据，提高了消息的处理效率。

熟悉负载均衡的朋友应该知道，当我们向某个服务器发送请求的时候，服务端可能会对请求做一个负载，将流量分发到不同的服务器，那在kafka中，如果某个topic有多个partition，producer又怎么知道该将数据发往哪个partition呢？kafka中有几个原则：

1、 partition在写入的时候可以指定需要写入的partition，如果有指定，则写入对应的partition。

2、 如果没有指定partition，但是设置了数据的key，则会根据key的值hash出一个partition。

3、 如果既没指定partition，又没有设置key，则会轮询选出一个partition。（视情况而定）

保证消息不丢失是一个消息队列中间件的基本保证，那producer在向kafka写入消息的时候，怎么保证消息不丢失呢？其实上面的写入流程图中有描述出来，那就是通过ACK应答机制！在生产者向队列写入数据的时候可以设置参数来确定是否确认kafka接收到数据，这个参数可设置的值为**0**、**1**、**all**。

`0:`  代表producer往集群发送数据不需要等到集群的返回，不确保消息发送成功。安全性最低但是效率最高。

`1:` 代表producer往集群发送数据只要leader应答就可以发送下一条，只确保leader发送成功。

`all:`代表producer往集群发送数据需要所有的follower都完成从leader的同步才会发送下一条，确保leader发送成功和所有的副本都完成备份。安全性最高，但是效率最低。

最后要注意的是，如果往不存在的topic写数据，能不能写入成功呢？kafka会自动创建topic，分区和副本的数量根据默认配置都是1。

#### **保存数据**

Producer将数据写入kafka后，集群就需要对数据进行保存了！kafka将数据保存在磁盘，可能在我们的一般的认知里，写入磁盘是比较耗时的操作，不适合这种高并发的组件。Kafka初始会单独开辟一块磁盘空间，顺序写入数据（效率比随机写入高）。

##### **Partition 结构**

前面说过了每个topic都可以分为一个或多个partition，如果你觉得topic比较抽象，那partition就是比较具体的东西了！Partition在服务器上的表现形式就是一个一个的文件夹，每个partition的文件夹下面会有多组segment文件，每组segment文件又包含.index文件、.log文件、.timeindex文件（早期版本中没有）三个文件， log文件就实际是存储message的地方，而index和timeindex文件为索引文件，用于检索消息。

![img](https://pic4.zhimg.com/v2-72e50c12fd9c6fbf58d3b5ca14c90623_b.jpg)

如上图，这个partition有三组segment文件，每个log文件的大小是一样的，但是存储的message数量是不一定相等的（每条的message大小不一致）。文件的命名是以该segment最小offset来命名的，如000.index存储offset为0~368795的消息，kafka就是利用分段+索引的方式来解决查找效率的问题。

##### **Message结构**

上面说到log文件就实际是存储message的地方，我们在producer往kafka写入的也是一条一条的message，那存储在log中的message是什么样子的呢？消息主要包含消息体、消息大小、offset、压缩类型……等等！我们重点需要知道的是下面三个：

1、 offset：offset是一个占8byte的有序id号，它可以唯一确定每条消息在parition内的位置！

2、 消息大小：消息大小占用4byte，用于描述消息的大小。

3、 消息体：消息体存放的是实际的消息数据（被压缩过），占用的空间根据具体的消息而不一样。

##### **存储策略**

无论消息是否被消费，kafka都会保存所有的消息。那对于旧数据有什么删除策略呢？

1、 基于时间，默认配置是168小时（7天）。

2、 基于大小，默认配置是1073741824。

需要注意的是，kafka读取特定消息的时间复杂度是O(1)，所以这里删除过期的文件并不会提高kafka的性能！

#### **消费数据**

消息存储在log文件后，消费者就可以进行消费了。在讲消息队列通信的两种模式的时候讲到过点对点模式和发布订阅模式。Kafka采用的是点对点的模式，消费者主动的去kafka集群拉取消息，与producer相同的是，消费者在拉取消息的时候也是找leader去拉取。

多个消费者可以组成一个消费者组（consumer group），每个消费者组都有一个组id！同一个消费组者的消费者可以消费同一topic下不同分区的数据，但是不会组内多个消费者消费同一分区的数据！。我们看下图：

![img](https://pic4.zhimg.com/v2-75a79cba9cfafe5c2f4d5349acb72207_b.jpg)

图示是消费者组内的消费者小于partition数量的情况，所以会出现某个消费者消费多个partition数据的情况，消费的速度也就不及只处理一个partition的消费者的处理速度！如果是消费者组的消费者多于partition的数量，那会不会出现多个消费者消费同一个partition的数据呢？上面已经提到过不会出现这种情况！多出来的消费者不消费任何partition的数据。所以在实际的应用中，建议**消费者组的consumer的数量与partition的数量一致**！

在保存数据的小节里面，我们聊到了partition划分为多组segment，每个segment又包含.log、.index、.timeindex文件，存放的每条message包含offset、消息大小、消息体……我们多次提到segment和offset，查找消息的时候是怎么利用segment+offset配合查找的呢？假如现在需要查找一个offset为368801的message是什么样的过程呢？我们先看看下面的图：

![img](https://pic1.zhimg.com/v2-87051d884344edf9f8fd97a3dacb32d0_b.jpg)

1、 先找到offset的368801message所在的segment文件（利用二分法查找），这里找到的就是在第二个segment文件。

2、 打开找到的segment中的.index文件（也就是368796.index文件，该文件起始偏移量为368796+1，我们要查找的offset为368801的message在该index内的偏移量为368796+5=368801，所以这里要查找的**相对offset**为5）。由于该文件采用的是稀疏索引的方式存储着相对offset及对应message物理偏移量的关系，所以直接找相对offset为5的索引找不到，这里同样利用二分法查找相对offset小于或者等于指定的相对offset的索引条目中最大的那个相对offset，所以找到的是相对offset为4的这个索引。

3、 根据找到的相对offset为4的索引确定message存储的物理偏移位置为256。打开数据文件，从位置为256的那个地方开始顺序扫描直到找到offset为368801的那条Message。

这套机制是建立在offset为有序的基础上，利用**segment**+**有序offset**+**稀疏索引**+**二分查找**+**顺序查找**等多种手段来高效的查找数据！至此，消费者就能拿到需要处理的数据进行处理了。那每个消费者又是怎么记录自己消费的位置呢？在早期的版本中，消费者将消费到的offset维护zookeeper中，consumer每间隔一段时间上报一次，这里容易导致重复消费，且性能不好！在新的版本中消费者消费到的offset已经直接维护在kafk集群的__consumer_offsets这个topic中！