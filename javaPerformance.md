# javaPerformance

## 介绍

jvm接收两种标志：boolean flag，需要参数的标志

Boolean flags use this syntax: -XX:+*FlagName* enables the flag, and -XX:-*FlagName* disables the flag.

不应该过早优化的重点是：最后，您应该编写干净，直接，易于阅读和理解的代码。在这种情况下，“优化”应理解为意味着采用算法和设计更改，这些更改会使程序结构复杂但提供更好的性能。确实最好不要进行此类优化，直到对程序进行性能分析表明执行这些优化有很大的好处之前。

```java
log.log(Level.FINE, "I am here, and the value of X is "+ calcX() + " and Y is " + calcY());
```

避免了不必要的日志打印调用，而且可以避免字符串连接：

```java
if (log.isLoggable(Level.FINE)) { 
	log.log(Level.FINE,"I am here, and the value of X is {} and Y is {}",new Object[]{calcX(), calcY()});
}
```

### Look Elsewhere: The Database Is Always the Bottleneck（数据库永远是瓶颈）

出现性能问题，常见案例分析表明，首先要考虑系统的最新部分（通常是JVM中的应用程序），但要准备研究环境的每个可能组件。

另一方面，请不要忽略最初的分析。如果数据库是瓶颈（这里有个提示:它是），那么调整访问数据库的Java应用程序将根本无法提高整体性能。实际上，这可能适得其反。通常，当负载增加到负担过重的系统中时，该系统的性能会变差。如果在Java应用程序中进行了某些更改，使其更加高效（这只会增加已经超载的数据库的负载）总体性能实际上可能会下降。这样一来，危险就得出了不正确的结论，即不应使用特定的JVM改进。

[这个原则（限制系统中运行不良的组件的负载会降低整个系统的运行速度）并不局限于数据库。当将负载添加到受CPU约束的应用程序服务器时，或者如果更多线程开始访问已经有线程在等待它的锁，或者在许多其他情况下，它将适用。](part242.htm#bookmark636)[第](part242.htm#bookmark636)9[章](part242.htm#bookmark636)[显示了一个仅涉及JVM的极端示例](part242.htm#bookmark636)。

### 对于通常的情况优化

将所有性能方面都视为同等重要，这是很诱人的，尤其是考虑到“千分之多的死亡”综合症。但是应该将重点放在常见的用例场景上。

该原则以几种方式体现出来：

[•通过对代码进行概要分析并专注于花费最多时间的配置文件中的操作来优化代码。但是请注意，这并不意味着仅查看配置文件中的叶子方法（请参见](part53.htm#bookmark144)第3章）。

•将Occam的Razor应用于诊断性能问题。对性能问题的最简单解释是最可能的原因：新代码中的性能错误比计算机上的配置问题更有可能发生，而机器上的配置问题则比JVM或操作系统中的错误更有可能发生。确实存在隐晦的错误，并且由于排除了导致性能问题的更可靠原因，因此有可能以某种方式使所涉及的测试用例触发了此类潜在错误。但是不要先跳到不太可能的情况。

•为应用程序中最常见的操作编写简单的算法。以一个估计一些数学公式的程序为例，用户可以在其中确定自己想要的答案是在10％的误差范围内还是1％的误差范围内。如果大多数用户对10％的余量感到满意，则可以优化该代码路径-即使这意味着减慢提供1％的误差余量的代码。

### 微基准测试（优化）

这些类别中的第一个是微基准。微基准测试是一种旨在测量很小的性能单位的测试：

调用同步方法与非同步方法的时间；

创建线程与使用线程池的开销；

执行一种算术算法与另一种实现的时间；等等。微基准测试似乎是一个好主意，但很难正确编写。考虑以下代码，这是一种尝试编写微基准测试的尝试，该微基准测试用于测试计算第50个斐波那契数的方法的不同实现的性能：

```java
public void doTest() {
// Main Loop
double l;
long then = System.currentTimeMillis();
for (int i = 0; i < nLoops; i++) { 
l = fibImpl1(50);
}
...
long now = System.currentTimeMillis(); 
System.out.println("Elapsed time: " + (now - then));
}


private double fibImpl1(int n) {
if (n < 0) throw new IllegalArgumentException("Must be > 0");
if (n == 0) return 0d;
if (n == 1) return 1d;
double d = fibImpl1(n - 2) + fibImpl(n - 1);
if (Double.isInfinite(d)) throw new ArithmeticException("Overflow");
return d;
}
```

解决该特定问题的方法是：

确保读取每个结果，而不是简单地写入。实际上，将l的定义从局部变量更改为实例变量（使用volatile关键字声明）将可以测量该方法的性能。（l实例变量必须声明为volatile的原因[可以在](part242.htm#bookmark636)第9章中[找到](part242.htm#bookmark636)。）

考虑两个线程在微基准测试中调用同步方法的情况。由于基准代码很小，因此大多数代码将在该同步方法中执行。即使整个微基准测试中只有50％位于同步方法之内，只有两个线程尝试同时执行同步方法的几率也很高。结果，基准测试将运行非常缓慢，并且随着添加更多线程，由争用增加引起的性能问题将变得更糟。最终的结果是，测试最终将衡量JVM如何处理争用而不是微基准测试的目标。

#### 微基准测试不得包含多余的操作

即使那样，仍然存在潜在的陷阱。此代码仅执行一个操作：

计算第50个斐波那契数。一个非常聪明的编译器可以找出并执行一次循环，或者至少丢弃一些循环迭代，因为这些操作是多余的。

此外，fibImpl（1000）的性能可能与fibImpl（1）的性能有很大不同。如果目标是比较不同实施的性能，则必须考虑一定范围的输入值。

为了克服这个问题，传递给fibImpl1（）方法的参数必须变化。解决方案是使用随机值，但也必须小心进行。

编码使用随机数生成器的简单方法是按以下方式处理循环：

```
for (int i = 0; i < nLoops; i++) {
l = fibImpl1(random.nextInteger());
}
```

现在，执行循环的时间中包括了计算随机数的时间，因此测试现在将计算nLoops次的斐波那契数列的时间加上生成nLoops个随机整数的时间。这可能不是目标。

在微基准测试中，必须预先计算输入值，例如：

```java
int[] input = new int[nLoops];

for (int i = 0; i < nLoops; i++) { 
    input[i] = random.nextInt();
}

long then = System.currentTimeMillis();
for (int i = 0; i < nLoops; i++) {

try {

l = fibImpl1(input[i]);

} catch (IllegalArgumentException iae) {

}
}
long now = System.currentTimeMillis();
```

#### 微基准测试必须测量正确的输入

这里的第三个陷阱是测试的输入范围：

选择任意随机值不一定代表如何使用代码。在这种情况下，对被测方法的一半调用（任何带有负值的调用）都会立即引发异常。只要输入参数大于1476，就会抛出异常，因为那是可以用双精度表示的最大斐波那契数。

在斐波那契计算明显更快但在计算结束之前未检测到异常情况的实现中会发生什么？考虑以下替代实现：

```java
public double fibImplSlow(int n) {

	if (n < 0) throw new IllegalArgumentException("Must be > 0"); 
    if (n > 1476) throw new ArithmeticException("Must be < 1476"); 
    return verySlowImpl(n);
}
```

很难想象实现会比原始的递归实现慢，但是假定在此代码中已设计并使用了一个实现。在非常宽的输入值范围内，将该实现与原始实现进行比较将显示此新实现比原始实现快得多，这是因为方法开始时进行了范围检查。

如果在现实世界中，用户只会向该方法传递小于100的值，那么这种比较将给我们错误的答案。在常见情况下，fibImpl（）[方法会更快，并且如](part23.htm#bookmark21)第1章所述，我们应针对常见情况进行优化。（这显然是一个人为的示例，仅向原始实现添加边界测试就可以使其成为更好的实现。在一般情况下，这可能是不可能的。）

**What About a Warm-Up Period?**(预热期)

[Java的性能特征之一是代码执行得越多，性能就会越好，这是](part92.htm#bookmark248)[第](part92.htm#bookmark248)4[章中](part92.htm#bookmark248)[讨论的主题](part92.htm#bookmark248)。因此，微基准测试必须包含一个预热期，这使编译器有机会生成最佳代码。

本章稍后将详细讨论预热期的优缺点。对于微基准测试，需要预热时间；否则，性能指标将衡量编译的性能，而不是它要衡量的代码。

综上所述，微基准的正确编码如下所示：

```java
public class FibonacciTest {

	private volatile double l; 
    private int nLoops; private int[] input;


public static void main(String[] args) {

	FibonacciTest ft = new FibonacciTest(Integer.parseInt(args[0])); 
    ft.doTest(true);

	ft.doTest(false);

}



private FibonacciTest(int n) {
    nLoops = n;

	input = new int[nLoops]; 
    Random r = new Random();

for (int i = 0; i < nLoops; i++) {
    input[i] = r.nextInt(100);

}

}



private void doTest(boolean isWarmup) {
    long then = System.currentTimeMillis(); 
    for (int i = 0; i < nLoops; i++) {
	l = fibImpl1(input[i]);
}

if (!isWarmup) {
	long now = System.currentTimeMillis(); 
    System.out.println("Elapsed time: " + (now - then));
}
}

private double fibImpl1(int n) {

if (n < 0) throw new IllegalArgumentException("Must be > 0");

if (n == 0) return 0d;

if (n == 1) return 1d;

double d = fibImpl1(n - 2) + fibImpl(n - 1);

if (Double.isInfinite(d)) throw new ArithmeticException("Overflow");

return d;

}
}
```

甚至这个微基准测试都测量了一些与Fibonacci实现无关的事情：在设置对fibImpl1（）方法的调用时存在一定数量的循环和方法开销，并且还需要将每个结果写入volatile变量高架。

还要注意其他编译效果。编译器使用代码的配置文件反馈来确定在编译方法时要采用的最佳优化。

配置文件反馈基于频繁调用的方法，调用它们时的堆栈深度，其参数的实际类型（包括子类）等等，这取决于代码实际运行的环境。与在应用程序中使用相同的代码时，编译器经常会在微基准测试中对代码进行不同的优化。如果同一类测量斐波那契方法的第二种实现，则可能发生各种编译效果，尤其是如果实现发生在不同的类中。

[最后，存在微基准实际上意味着什么的问题。对于大量循环，基准（例如此处讨论的基准）中的整体时间差异可能以秒为单位进行度量，但每次迭代的差异通常以纳秒为单位进行度量。是的，十亿分之一秒的总和，“一千次裁员死亡”是一个常见的性能问题。但是，尤其是在回归测试中，请考虑在纳秒级跟踪某些东西是否真正有意义。在每次访问将要访问数百万次的集合时，节省几纳秒的时间可能很重要（例如，请参见](part351.htm#bookmark914)[第](part351.htm#bookmark914)12[章](part351.htm#bookmark914)）。对于不经常发生的操作（例如，每个servlet请求可能一次），修复微基准所发现的纳秒级回归将占用时间，而这些时间本可以更有利地用于优化其他操作。

编写微基准测试很难。有用的时间非常有限。请注意所涉及的陷阱，并确定获得合理的微基准测试所涉及的工作是否值得受益—或者集中精力进行更多的宏观水平测试是否更好。



Macrobenchmarks

衡量应用程序性能的最佳方法是应用程序本身，以及它使用的所有外部资源。如果应用程序通常通过进行LDAP调用来检查用户的凭据，则应在该模式下对其进行测试。进行LDAP调用存根对于模块级测试可能很有意义，但是必须在完整配置下对应用程序进行测试。

随着应用程序的增长，这一准则变得越来越重要，难以实现和实现。复杂的系统不仅仅是它们各个部分的总和。组装这些零件时，它们的行为会大不相同。例如，模拟数据库调用可能意味着您不再需要担心数据库性能-嘿，您是Java人士。您为什么要应对别人的绩效问题？但是数据库连接会为其缓冲区占用大量堆空间；当通过网络发送更多数据时，网络变得饱和；调用更简单的方法集时，代码的优化方式有所不同（与JDBC驱动程序中的复杂代码相反）；与较长的代码路径相比，CPU可以更有效地管线化和缓存较短的代码路径；等等。

测试完整应用程序的另一个原因是资源分配之一。在理想的情况下，将有足够的时间来优化应用程序中的每一行代码。

在现实世界中，最后期限迫在眉睫，仅优化复杂环境的一部分可能不会立即产生收益。

[考虑](part39.htm#bookmark82)图2-1[中](part39.htm#bookmark82)所示[的数据流](part39.htm#bookmark82)。数据来自用户，进行一些专有业务计算，从数据库中加载一些基于该数据的数据，进行更多专有计算，将更改后的数据存储回数据库，并将答案发送回用户。每个框中的数字是每秒进行隔离测试时模块可以处理的每秒请求数（例如200 RPS）。

![图片](file:///E:/oldF/learningDocument/book_html/java_performance/Java_Performance/Image_028.png)

图2-1。典型程序流程

从业务角度来看，专有计算是最重要的；它们是程序存在的原因，也是我们获得报酬的原因。但是，在本示例中，使其速度提高100％绝对不会带来任何好处。可以将任何应用程序（包括一个独立的JVM）建模为一系列这样的步骤，其中数据以框的效率决定的速度从框（模块，子系统等）中流出。（在该模型中，该时间包括该子系统中的代码，还包括网络传输时间，磁盘传输时间等。在模块模型中，该时间仅包括该模块的代码。）数据在以下位置流入子系统由上一个框的输出速率确定的速率。

假设对业务计算进行了算法改进，使其可以处理200 RPS；注入系统的负载相应增加。LDAP系统可以处理增加的负载：到目前为止，效果很好，并且200 RPS将流入计算模块，该模块将输出200 RPS。

但是数据库仍然只能处理100 RPS。即使200 RPS流入数据库，也只有100 RPS流出数据库并流入其他模块。即使业务逻辑的效率提高了一倍，系统的总吞吐量仍仅为100 RPS。在花时间改善环境的其他方面之前，进一步改善业务逻辑的尝试将被证明是徒劳的。

#### 使用多个JVM进行完整的系统测试

当在同一硬件上同时运行多个应用程序时，将发生一个测试整个应用程序的特别重要的情况。默认情况下，JVM的许多方面都进行了调整，以假定所有机器资源均可供他们使用，并且如果对这些JVM进行单独测试，它们将表现良好。如果在存在其他应用程序（包括但不限于其他JVM）的情况下对它们进行了测试，则它们的性能将大不相同。

在后面的章节中将给出示例，但是这里是一个快速预览：执行GC周期时，一个JVM（以其默认配置）将驱动计算机上的CPU使用率达到所有处理器的100％。如果将CPU作为程序执行期间的平均值来衡量，则使用率可能平均为40％，但这确实意味着CPU有时繁忙30％，有时繁忙100％。当JVM独立运行时，可能会很好，但是如果JVM与其他应用程序同时运行，则在GC期间它将无法获得100％的计算机CPU。它的性能将与它自己运行时明显不同。

这就是为什么微基准测试和模块级基准测试不一定能为您提供应用程序性能的全貌的另一个原因。

在此示例中，并非完全浪费了优化计算所花费的时间：一旦将精力投入到系统中其他地方的瓶颈中，性能优势将最终显而易见。相反，这是一个优先事项：

如果不测试整个应用程序，就不可能确定花时间在性能工作上会得到回报。

#### 总结

我同时使用Java SE和EE的性能，并且每个小组都有一组测试，它们将它们描述为微基准。对于Java SE工程师而言，该术语表示的示例甚至比第一部分中的示例还要小：对非常小的内容的度量。Java EE工程师倾向于使用该术语将其应用于其他方面：衡量性能的一个方面，但仍然执行大量代码的基准。

Java EE“微基准”的一个示例可能是衡量从应用服务器返回简单JSP响应的速度的方法。与传统的微生物标记相比，这种请求所涉及的代码是相当多的：

有许多套接字管理代码，用于读取请求的代码，用于查找（并可能编译）JSP的代码，用于编写答案的代码，等等。从传统的角度来看，这不是微基准测试。

这种测试也不是宏基准测试：没有安全性（例如，用户未登录到应用程序），没有会话管理以及没有使用其他Java EE功能的主机。因为它只是实际应用程序的一个子集，所以它落在中间位置—它是中基准。Mesobenchmarks不仅限于Java EE领域：这是我用于基准测试的术语，它可以完成一些实际工作，但不是完整的应用程序。

中基准比微基准具有更少的陷阱，并且比宏基准更易于使用。中基准不太可能包含可以由编译器优化的大量死代码（除非死代码确实存在于应用程序中，在这种情况下将其优化是一件好事）。Mesobenchmark易于线程化：

与在完整应用程序中运行时所遇到的同步瓶颈相比，代码仍然更有可能遇到更多的同步瓶颈，但是这些瓶颈是真正的应用程序最终将在较大负载下在大型硬件系统上遇到的瓶颈。

[但是，中基准并不是完美的。使用这样的基准比较两个应用程序服务器的性能的开发人员可能容易误入歧途。考虑](part40.htm#bookmark88)表2-1中[所示的两个应用服务器的假设响应时间](part40.htm#bookmark88)。

表2-1。两个应用程序服务器的假想响应时间

​                  测试App服务器1   App服务器2

简单的JSP 19毫秒                   50毫秒

会话为      75毫秒的JSP          50毫秒

仅使用简单的JSP比较两个服务器性能的开发人员可能不会意识到服务器2正在为每个请求自动创建会话。然后，她可能会得出结论，服务器1将为她提供最快的性能。但是，如果她的应用程序总是创建一个会话（这是典型的），那么她将做出错误的选择，因为创建会话需要花费更多的服务器1。（后续调用的性能是否有所不同是另一个要考虑的问题，但是无法根据此数据预测一旦创建会话后哪个服务器的性能会更好。）

即便如此，中基准测试还是测试全面应用程序的合理替代方法。与微基准的性能特征相比，它们的性能特征与实际应用更加紧密地吻合。当然这里有一个连续体。本章后面的部分介绍了后续各章中许多示例所用的通用应用程序的概述。该应用程序具有EE模式，但是在大多数示例中，该模式不使用会话复制（高可用性）或基于EE平台的安全性，尽管它可以访问企业资源（即数据库）。它只是组成随机数据。在SE模式下，它模仿一些实际（但快速）的计算：例如，没有GUI或用户交互发生。

```
Mesobenchmarks也适用于自动化测试，尤其是在模块级别。
```

#### 常见代码示例

本书中的许多示例均基于一个示例应用程序，该示例应用程序计算了某个日期范围内股票的“历史”高低价格，以及该时间段内的标准差。这里的历史用引号引起来，因为在应用程序中，所有数据都是虚构的。价格和股票代码是随机生成的。

[本书所有示例的完整源代码都在我的](https://github.com/ScottOaks/JavaPerformanceTuning)GitHub页面上，但是本节介绍了有关代码的基本要点。应用程序内的基本对象是StockPrice对象，它代表给定日期的股票价格范围：

```java
public interface StockPrice {
    String getSymbol(); 
    Date getDate();
    
	BigDecimal getClosingPrice(); 
    
    BigDecimal getHigh(); 
    
    BigDecimal getLow(); 
    
    BigDecimal getOpeningPrice(); 
    
    boolean isYearHigh();

	boolean isYearLow();

	Collection<? extends StockOptionPrice> getOptions();

}
```

示例应用程序通常处理这些价格的集合，这些价格代表一段时间（例如1年或25年，取决于示例）中的库存历史记录：

```java
public interface StockPriceHistory { 
    
    StockPrice getPrice(Date d);

	Collection<StockPrice> getPrices(Date startDate, Date endDate);
	Map<Date, StockPrice> getAllEntries();
    Map<BigDecimal,ArrayList<Date>> getHistogram();

	BigDecimal getAveragePrice();
    Date getFirstDate();

	BigDecimal getHighPrice();
    Date getLastDate();
    BigDecimal getLowPrice();
    BigDecimal getStdDev();
    String getSymbol();

}

//The basic implementation of this class loads a set of prices from the database:
//这个类的基本实现从数据库中加载一组价格:
public class StockPriceHistoryImpl implements StockPriceHistory {


public StockPriceHistoryImpl(String s, Date startDate, Date endDate, EntityManager em) {

	Date curDate = new Date(startDate.getTime()); 
	symbol = s;

	while (!curDate.after(endDate)) {

		StockPriceImpl sp = em.find(StockPriceImpl.class,new StockPricePK(s, (Date) 			curDate.clone()));
		if (sp != null) {

			Date d = (Date) curDate.clone();

		if (firstDate == null) { firstDate = d;

		}

		prices.put(d, sp); lastDate = d;

	}

	curDate.setTime(curDate.getTime() + msPerDay);

	}

}

...

}
```

[样本的体系结构旨在从数据库中加载，该功能将在](part315.htm#bookmark829)第11章[的示例中使用](part315.htm#bookmark829)[。但是，为了便于运行示例，大多数情况下，他们将使用模拟实体管理器来为系列生成随机数据。从本质上讲，大多数示例都是适合于说明当前性能问题的模块级中标，但是当整个应用程序运行时，我们只能对应用程序的实际性能有所了解（如](part315.htm#bookmark829)第11章中所述）。

一个警告是，许多示例因此取决于所使用的随机数发生器的性能。与微基准示例不同，这是设计使然，因为它可以说明Java中的几个性能问题。（就此而言，示例的目的是测量某种任意事物的性能，而随机数生成器的性能符合该目标。这与微基准测试完全不同，后者包括生成随机数的时间。 ‐贝尔会影响整体计算。）

这些示例还严重依赖于BigDecimal类的性能，该类用于存储所有数据点。这是存储货币的标准选择

数据; 如果将货币数据存储为原始的双重对象，那么半美分和较小金额的取整就变得很成问题。从书写示例的角度来看，该选择也很有用，因为它允许进行一些“业务逻辑”或冗长的计算，尤其是在计算一系列价格的标准差时。标准偏差取决于知道BigDecimal数的平方根。标准的Java API不提供这样的例程，但是示例使用此方法：

```java
public static BigDecimal sqrtB(BigDecimal bd) { 
    
    BigDecimal initial = bd;

	BigDecimal diff;

do {
	BigDecimal sDivX = bd.divide(initial, 8, RoundingMode.FLOOR); 
    BigDecimal sum = sDivX.add(initial);

	BigDecimal div = sum.divide(TWO, 8, RoundingMode.FLOOR); 
    diff = div.subtract(initial).abs();

	diff.setScale(8, RoundingMode.FLOOR); initial = div;

} while (diff.compareTo(error) > 0);

return initial;

}
```

[这是用于估计数字平方根的巴比伦方法的实现。这不是最有效的实现。特别是，最初的猜测可能会更好，这样可以节省一些迭代。这是有意的，因为它允许计算花费一些时间（模拟业务逻辑），尽管它确实说明了](part23.htm#bookmark21)[第](part23.htm#bookmark21)1[章中](part23.htm#bookmark21)[的基本观点](part23.htm#bookmark21)：通常，使Java代码更快的更好方法是编写更好的算法，而与任何Java无关调整或采用的Java编码实践。

StockPriceHistory接口的实现的标准差，平均价格和直方图都是派生值。在不同的示例中，这些值将被急切地计算（当从实体管理器加载数据时）或懒惰地（计算检索数据的方法时）。同样，StockPrice接口引用StockOptionPrice接口，该接口是给定股票在给定日期的某些期权的价格。可以从实体管理器中积极或懒惰地检索那些选项值。在这两种情况下，这些接口的定义都可以在不同情况下比较这些不同的方法。

这些接口也自然适合Java EE应用程序：用户可以访问JSP页面，该页面允许她输入感兴趣的股票的代码和日期范围。在标准示例中，请求将通过解析的标准servlet进行。输入参数，使用嵌入式Java持久性API（JPA）bean调用无状态Enterprise JavaBean（EJB）以获取基础数据，并将响应转发到Java Server Pages（JSP）页面，该页面格式化基础数据转换成HTML演示文稿：

```java
protected void processRequest(HttpServletRequest request, HttpServletResponse response)throws ServletException, IOException {

try {

String symbol = request.getParameter("symbol");

if (symbol == null) {

symbol = StockPriceUtils.getRandomSymbol();

}

//... similar processing for date and other params...对日期和其他参数进行类似的处理

StockPriceHistory sph; 
DateFormat df = localDf.get();

sph = stockSessionBean.getHistory(symbol, df.parse(startDate), df.parse(endDate), doMock, impl);

String saveSession = request.getParameter("save");

if (saveSession != null) {

//.... Store the data in the user's session ....将数据存储在用户的会话中

//.... Optionally store the data in a global cache for可选地将数据存储在全局缓存中

//.... use by other requests由其他请求使用

}

if (request.getParameter("long") == null) {

// Send back a page with about 4K of data返回一个包含大约4K数据的页面

request.getRequestDispatcher("history.jsp"). forward(request, response);

}else {

// Send back a page with about 100K of data返回一个包含大约100K数据的页面

request.getRequestDispatcher("longhistory.jsp"). forward(request, response);
}

}
```



此类可以注入历史Bean的不同实现（尤其是用于急切或延迟初始化）。它可以选择缓存从后端数据库（或模拟实体管理器）检索到的数据。这些是处理企业应用程序性能时的常用选项（特别是在中间层缓存数据有时被认为是应用程序服务器的最大性能优势）。本书中的示例还将研究这些折衷。

被测系统**System Under Test**

即使本书主要侧重于软件，基准测试也可以衡量它们所运行的硬件。

大部分情况下，本书中的示例都在我的台式机系统上运行，该台式机系统具有AMD Athlon X4 640 CPU，该CPU具有四个内核（四个逻辑CPU）和8 GB的物理内存，并运行Ubuntu Linux 12.04 LTS。

#### Understand Throughput, Batching, and Response Time（了解吞吐量，批处理，和响应时间）

#### 经过时间（批次）测量

衡量绩效的最简单方法是查看完成一项任务需要多长时间：检索25年内10,000只股票的历史记录，并计算这些价格的标准差；生成公司50,000名员工的工资福利报告；执行一次循环1,000,000次。

[在非Java世界中，此测试非常简单：编写应用程序，并测量其执行时间。在Java世界中，这有一个缺点：即时编译。该过程在](part92.htm#bookmark248)第4章[中进行了描述](part92.htm#bookmark248)。本质上，这意味着代码需要花费几分钟（或更长时间）来完全优化并以最佳性能运行。因此（或其他）原因，对Java的性能研究非常关注预热期：性能通常是在所讨论的代码执行了足够长的时间以进行编译和优化之后才进行测量。

暖化应用程序的其他因素

通常在等待编译器优化所讨论的代码方面对应用程序进行预热，但是还有其他一些因素可能会影响代码性能，具体取决于运行时间。

[例如，JPA通常将缓存从数据库中读取的数据（请参见](part315.htm#bookmark829)[第](part315.htm#bookmark829)11[章](part315.htm#bookmark829)）。第二次使用数据时，操作通常会更快，因为可以从缓存中获取数据，而不需要访问数据库。同样，当应用程序读取文件时，操作系统通常会将文件分页到内存中。随后读取同一文件（例如，在循环中以测量性能）的测试将第二次运行得更快，因为数据已经驻留在计算机的主内存中，实际上不需要从磁盘读取数据。

通常，可以在许多地方（并非所有人都显而易见）缓存数据以及预热期很重要。

另一方面，在许多情况下，应用程序从头到尾的性能至关重要。处理10,000个数据元素的报告生成器将在一定时间内完成；对于最终用户而言，头5,000个元素的处理速度比后5,000个元素慢50％无关紧要。甚至在像应用程序服务器这样的服务器性能肯定会随着时间而提高的情况下，初始性能也很重要。应用服务器可能需要45分钟在某些配置中达到最高性能。对于那段时间访问应用程序的用户而言，预热期间的性能确实很重要。

由于这些原因，本书中的许多示例都是面向批处理的（即使这很少见）。

####  吞吐量测量（Throughput Measurements）

吞吐量测量基于一定时间内可以完成的工作量。尽管最常见的吞吐量测量示例涉及服务器处理客户端馈送的数据，但这并不是绝对必要的：

单个独立应用程序可以像测量经过时间一样轻松地测量吞吐量。

在客户端服务器测试中，吞吐量测量意味着客户端没有思考时间。如果只有一个客户端，则该客户端将请求发送到服务器。收到响应后，它将立即发送一个新请求。这个过程继续进行；在测试结束时，客户端报告其已完成的操作总数。通常，客户端有多个线程在做同一件事，而吞吐量是所有客户端完成的操作数的总和。通常，此数字报告为每秒的操作数，而不是测量期间的操作总数。此度量通常称为每秒事务（TPS），每秒请求（RPS）或每秒操作（OPS）。

所有客户端-服务器测试都存在客户端无法将数据足够快地发送到服务器的风险。发生这种情况的原因是，客户端计算机上没有足够的CPU周期来运行所需数量的客户端线程，或者因为客户端在发送新请求之前必须花费大量时间来处理请求。在这些情况下，测试实际上是在衡量客户端性能，而不是服务器性能，这通常不是目标。

这种风险取决于每个客户端线程执行的工作量（以及客户端计算机的大小和配置）。零思考时间（面向吞吐量）测试很可能会遇到这种情况，因为每个客户端线程都在执行大量工作。因此，与测试响应时间的相应测试相比，吞吐量测试通常使用更少的客户端线程（更少的负载）执行。

测试吞吐量的测试通常也会报告其请求的平均响应时间。这是一条有趣的信息，但是除非报告的吞吐量相同，否则该数字的更改并不表示性能问题。能够以0.5秒的响应时间维持500个OPS的服务器，比报告0.3秒的响应时间但仅400 OPS的服务器，性能要更好。

吞吐量测量几乎总是在适当的预热期后进行的，特别是因为所测量的不是固定的工作。

##### Response Time Tests 响应时间测试

最后一个通用测试是测量响应时间的测试：从客户端发送请求到接收响应之间经过的时间。

响应时间测试和吞吐量测试（假设后者是基于客户端-服务器的）之间的区别在于，响应时间测试中的客户端线程在两次操作之间会休眠一段时间。这称为*思考时间*。响应时间测试旨在更紧密地模仿用户的操作：她在浏览器中输入URL，花一些时间阅读返回的页面，单击页面中的链接，花一些时间阅读该页面，等等上。

将思考时间引入测试后，吞吐量将变得固定：在给定思考时间下执行请求的给定数量的客户端将始终产生相同的TPS（略有差异；请参见侧栏）。那时，重要的衡量标准是请求的响应时间：服务器的有效性取决于服务器对固定负载的响应速度。

### 思考时间和吞吐量

客户包括思考时间的测试吞吐量可以通过两种方式进行衡量。最简单的方法是让客户端在两次请求之间睡眠一段时间：

```java
while (!done) {
time = executeOperation(); 
Thread.currentThread().sleep(30*1000);
}
```

在这种情况下，吞吐量在某种程度上取决于响应时间。如果响应时间为1秒，则意味着客户端将每31秒发送一次请求，这将产生0.032 OPS的吞吐量。如果响应时间为2秒，则每个客户端将每32秒发送一次请求，从而产生0.031 OPS的吞吐量。

另一种选择是循环时间（而不是思考时间）。周期时间将两次请求之间的总时间设置为30秒，因此客户端休眠的时间取决于响应时间：

```java
while (!done) {
time = executeOperation(); 
Thread.currentThread().sleep(30*1000 - time);

}
```

无论响应时间如何（假设响应时间始终小于30秒），此替代方案将为每个客户端提供0.033 OPS的固定吞吐量。

测试工具中的思考时间通常因设计而异。他们将平均一个特定值，但使用随机变化更好地模拟用户的行为。此外，线程调度永远不会是完全实时的，因此客户端发送请求之间的实际时间会略有不同。

![image](file:///E:/oldF/learningDocument/book_html/java_performance/Java_Performance/Image_033.png)

结果，即使使用提供周期时间而不是思考时间的工具，两次运行之间的报告吞吐量也会略有不同。但是，如果吞吐量远未达到预期值，则在执行测试时会出现问题。

有两种测量响应时间的方法。可以将响应时间报告为平均值：

将各个时间加在一起，然后除以请求数。响应时间也可以报告为百分比请求，例如响应时间的90％。如果90％的响应时间小于1.5秒，而10％的响应时间大于1.5秒，则1.5秒是第90％的响应时间。

这两个数字之间的区别是离群值影响平均值计算的方式：由于它们被包括在平均值中，因此较大的离群值将对平均响应时间产生较大影响。

图2-2显示了20条请求的图表，其中响应时间的范围较为典型。响应时间为1到5秒。平均响应时间（沿x轴的下部粗线表示）为2.35秒，其中90％的响应发生在4秒或更短的时间内（沿x轴的上部粗线表示）。

![image](file:///E:/oldF/learningDocument/book_html/java_performance/Java_Performance/Image_034.png)

图2-2。典型的响应时间

[这是行为良好的测试的通常情况。异常值可能会使该分析偏斜，](part47.htm#bookmark104)如图2-3中[的数据](part47.htm#bookmark104)所示。

了解吞吐量，批处理和响应时间| 27

图2-3。一组具有异常值的响应时间

该数据集包括一个巨大的异常值：一个请求花费了100秒。结果，第90％的位置和平均响应时间相反。平均响应时间为5.95秒，但90％的响应时间为1.0秒。在这种情况下，应着重减少离群值的影响（这将缩短平均响应时间）。

负载发生器 **Load Generators**

[有许多开源和商业负载生成工具。本书中的示例使用](http://faban.org/)Faban（一种基于Java的开源负载生成器）。Faban带有一个简单程序（fhb），可用于测量简单URL的性能：

% **fhb -W 1000 -r 300/300/60 -c 25 http://host:port/StockServlet?stock=SDO**

运算/秒：8.247

错误百分比：0.0

平均 时间：0.022

ops/sec: 8.247

% errors: 0.0

avg. time: 0.022

这样的异常值通常很少见，尽管由于GC引入了暂停时间，它们在Java应用程序中更容易出现。（并不是说应该期望垃圾回收会带来100秒的延迟，但特别是对于平均响应时间较短的测试，GC暂停可能会引入明显的异常值。）在性能测试中，通常将重点放在响应的90％上。时间（有时是95％或99％的响应时间；对于90％而言，没有什么神奇的）。如果您只能关注一个数字，则基于百分位数的数字是更好的选择，因为获得较小的数字将使大多数用户受益。但是最好同时查看平均响应时间和至少一个基于百分位数的响应时间，这样您就不会错过异常值较大的情况。

最长时间：0.045

90th ％：0.030

95th ％：0.035

99th ％：0.035

此示例度量了25个客户端（-c 25）向库存servlet发出请求（请求符号SDO）；每个请求都有一个1秒的循环时间（-W 1000）。基准测试有5分钟（300秒）的预热时间，然后是5分钟的测量时间和1分钟的下降时间（-r 300/300/60）。在测试之后，fhb报告测试的OPS和各种响应时间（并且由于该示例包括思考时间，因此响应时间是重要的指标，而OPS或多或少是恒定的）。

fhb可以使用有限的替换和具有多个URL的有限脚本来处理POST数据。对于更复杂的测试，Faban有一个有用的框架，可以用Java定义基准负载生成器。

快速总结

1.Java性能测试中很少使用面向批处理的测试（或任何没有预热期的测试），但是它们可以产生有价值的结果。

2.其他测试可以衡量吞吐量或响应时间，具体取决于负载是否以固定速率传入（即，基于模拟客户端的思考时间）。

#### Understand Variability 了解变异

​		第三个原则涉及了解测试结果如何随时间变化。处理完全相同的数据集的程序每次运行时都会产生不同的答案。计算机上的后台进程将影响应用程序，程序运行时网络将或多或少地变得拥塞，等等。好的基准测试也永远不会在每次运行时都处理完全相同的数据集。测试中会内置一些随机行为来模仿现实世界。这就产生了一个问题：将一次运行的结果与另一次运行的结果进行比较时，差异是由于回归还是由于测试的随机变化？

可以通过多次运行测试并平均那些结果来解决此问题。然后，当对要测试的代码进行更改时，可以多次重新运行测试，取平均结果，然后将两个平均值进行比较。听起来很简单。

不幸的是，它并非如此简单。理解差异何时是真正的回归，何时差异是随机变化是很困难的，这是科学引领道路的关键领域，但艺术将发挥作用。

当比较基准结果中的平均值时，不可能确切知道平均值的差异是真实的还是由随机波动引起的。最好的办法是假设“平均值是相同的”，然后确定这种说法正确的可能性。如果该陈述很可能是错误的，那么我们很容易相信平均值的差异（尽管我们永远无法100％确定）。

[测试此类更改的代码称为回归测试。在回归测试中，原始代码称为基准，新代码称为样本。以批处理程序为例，其中基线和样本均运行3次，得出](part49.htm#bookmark108)表2-2中[给出的时间](part49.htm#bookmark108)。

表2-2。假设时间执行两次测试

**基线           标本**

第一次迭代 1.0秒  0.5秒

第二次迭代  0.8秒  1.25秒

第三迭代     1.2秒     0.5秒

平均             1秒      0.75秒

​		样本的平均水平说代码提高了25％。我们如何有信心测试能够真正反映出25％的改善？情况看起来不错：三个样本值中的两个小于基线平均值，并且改进幅度很大-但是，当对这些结果执行本节中描述的分析时，结果表明样本和样本的概率基线具有相同的性能为43％。当观察到此类数字时，两种测试的基本性能有43％的时间相同。因此，性能差异只有57％的时间。顺便说一句，这与说57％的时间性能提高25％并不完全相同，但是稍晚一点就可以了。

​		这些概率似乎与预期不同的原因是由于结果差异很大。通常，一组结果的变化越大，就越难猜测平均值差异是真实的或由于随机机会而产生的概率。

​		这个数字（43％）是基于学生t检验的结果得出的，该结果是基于序列及其方差的统计分析。顺便说一下，学生是最早发布该测试的科学家的笔名；它并不是用这种方式来提醒您回忆研究生院，您（或至少是我）在统计学课上睡觉了。t检验产生一个称为*p值*的数字，它表示该检验的零假设为假的概率。（有几个程序和类库可以计算t检验结果; 该部分产生的数字来自使用Apache Commons Mathematics Library的TTest类。）

​		回归测试中的原假设是两个测试具有相同性能的假设。此示例的*p*值大约为43％，这意味着我们可以确信该系列收敛到相同的平均值是43％。相反，我们对该系列没有收敛到同一平均值的置信度是57％。

​		表示57％的时间序列未收敛到相同的平均值是什么意思？严格来说，这并不意味着我们对结果有25％的改善有57％的信心，而是意味着我们对结果有所不同有57％的信心。可能会改善25％，可能会改善125％；甚至可以想象，样品的性能实际上比基线差。最可能的可能性是测试中的差异与已测量的差异相似（尤其是当*p*值下降时），但是永远无法实现确定性。

**统计与语义**

表示t检验结果的正确方法是用这样的语句表达：样本有57％的概率与基线不同，而这种差异的最佳估计是25％。

​		呈现这些结果的常用方法是说，有57％的置信度，即结果改善了25％。尽管这不完全相同，并且会使统计人员感到疯狂，但它很容易采用速记方式，而且相差不远。概率分析总是涉及一些不确定性，准确地表达语义时可以更好地理解不确定性。但是，特别是在对底层问题已广为人知的竞技场中，不可避免地会出现一些语义捷径。

​		t检验通常与*α值*结合使用，*α值*是一个（有点任意）点，在该点上，结果被认为具有统计意义。通常将*α-*值设置为0.1，这意味着如果结果意味着样本和基线在同一时间的10％（0.1）相同（或者相反，则90％的时间），则认为该结果具有统计学意义。标本和基线之间有差异的时间）。其他常用的*α值*是0.5（95％）或0.01（99％）。如果*p*值小于1 *–α*值，则认为检验具有统计学意义。

​		因此，在代码中搜索回归的正确方法是确定统计显着性水平（例如90％），然后使用t检验确定样本和基线在统计显着性程度内是否不同。如果统计显著性测试失败，则必须小心理解其含义。在示例中，*p*值为0.43；我们不能说内部有统计意义90％的置信度表明结果表明平均值不同。检验在统计上不重要这一事实并不意味着它是无关紧要的结果；它只是意味着测试没有定论。

**统计上重要**

​		统计意义并不意味着统计意义。基线平均偏差为1秒的小基线和方差为1.01秒的小样本的*p*值可能为0.01：结果差异的可能性为99％。

​		差异本身仅为1％。现在说不同的测试显示样本和基线之间有10％的回归，但*p*值为0.2：无统计学意义。哪项测试需要所有时间中最宝贵的资源-额外的调查时间？

​		尽管对出现10％的差异的情况信心不足，但最好将时间花在调查该测试上（如果可能，从获取更多数据开始，以查看结果是否在统计上有意义）。仅仅因为1％的差异更有可能并不意味着它就更重要。

​		测试在统计上不确定的通常原因是样本中没有足够的数据。到目前为止，此处的示例已查看了在基线和样本中具有三个结果的系列。如果再添加三个结果怎么办？再次得出1、1.2和基线为0.8秒，样本为0.5、1.25和0.5秒？使用其他数据，*p*值从0.43下降到0.19：结果不同的概率从57％上升到81％。运行附加测试并再次添加三个数据点会将概率提高到91％，这与通常的统计意义水平相比。

​		运行附加测试直到达到统计显着性水平并不总是可行的。严格来说，也没有必要。即使通常选择是通用的，也可以选择确定统计意义的*α*值。一个*p* - 0.11值不是90％的置信水平内统计显著，但它是一个89％的置信水平内统计学显著。

​		这里的结论是回归测试不是一门黑白科学。您无法查看一系列数字（或它们的平均值）并做出比较它们的判断，而无需进行统计分析来了解这些数字的含义。但是，由于概率定律，即使是该分析也无法给出完全确定的答案。性能工程师的工作是查看数据，了解那些概率，并根据所有可用数据确定在哪里度过时间。

快速总结

1.正确确定两个测试的结果是否不同需要进行统计分析，以确保感知到的差异不是随机机会的结果。

2.严格的方法是使用学生的t检验比较结果。

3.来自t检验的数据告诉我们存在回归的可能性，但没有告诉我们应该忽略哪些回归，必须进行回归。找到平衡是性能工程的一部分。

#### 尽早测试，经常

​		第四点也是最后一点，性能极客（包括我）喜欢建议将性能测试作为开发周期的组成部分。在理想的情况下，将代码检入中央存储库时，性能测试将作为该过程的一部分运行。引入性能下降的代码将被阻止签入。

​		该建议与本章中的其他建议之间以及该建议与实际环境之间存在着内在的张力。良好的性能测试将包含许多代码-至少是中型的中基准。需要重复多次以建立信心，以确保旧代码和新代码之间发现的任何差异都是真实差异，而不仅仅是随机变化。在大型项目中，这可能需要几天或一周的时间，因此在将代码检入存储库之前对代码运行性能测试是不现实的。

​		典型的开发周期不会使事情变得容易。项目进度表通常会确定一个功能冻结日期：所有对代码的功能更改都必须在发布周期的某个较早时检入到存储库中，而其余的周期则专门用于消除任何错误（包括性能问题）。新版本。这会导致两个早期测试问题：

1.开发人员受时间限制，无法按计划签入代码；当时间表在所有初始代码都签入后才有时间解决时，他们将不愿意花时间解决性能问题。签入代码导致在周期初期导致1％的回归的开发人员将面临解决该问题的压力。 ; 等到功能冻结的晚上，开发人员可以检入导致20％回归的代码，然后再处理。

2.代码的性能特征将随着代码的变化而变化。这是测试整个应用程序的原则（除了可能发生的模块级测试）：堆使用率将发生变化，代码编译将发生变化，依此类推。

尽管存在这些挑战，但是即使无法立即解决问题，在开发过程中进行频繁的性能测试也很重要。引入导致5％的回归的代码的开发人员可能有计划在开发过程中解决该回归问题：也许她的代码取决于某些尚待集成的功能，并且当该功能可用时，可以进行一些小的调整回归消失。这是一个合理的位置，即使这意味着性能测试将不得不在5％的回归条件下维持数周（而不幸的是，但不可避免的问题是，该回归结果掩盖了其他回归结果）。

另一方面，如果新代码导致只能通过某些体系结构更改来修复的回归，则最好在其余代码开始依赖于新实现之前，尽快捕获并解决该回归问题。这是一种平衡的行为，需要分析和政治技巧。

如果遵循以下准则，则尽早进行频繁的测试最为有用：

自动化一切

所有性能测试都应编写脚本（或编写程序，尽管编写脚本通常更容易）。脚本必须能够安装新代码，将其配置到完整的环境中（创建数据库连接，设置用户帐户等），并运行测试集。但这还不止于此：脚本必须能够多次运行测试，对结果进行t检验分析，并生成报告，显示结果相同的置信度以及测得的差异如果它们不相同。

自动化必须在运行测试之前确保机器处于已知状态：它必须检查是否没有正在运行的异常进程，操作系统配置正确等等。仅当运行之间的环境相同时，性能测试才可重复。自动化必须照顾到这一点。

衡量一切

[自动化必须收集所有可能的数据，这将对以后的分析有用。这包括在整个运行过程中采样的系统信息：CPU使用率，磁盘使用率，网络使用率，内存使用率等。它包括来自应用程序的日志（包括应用程序生成的日志）和来自垃圾收集器的日志。理想情况下，它可以包括Java Flight Recorder（JFR）记录（请参见](part53.htm#bookmark144)[第](part53.htm#bookmark144)3[章](part53.htm#bookmark144)）或其他影响较小的概要分析信息，定期线程堆栈以及其他堆分析数据，例如直方图或完整堆转储（尽管特别是完整堆转储） ，占用大量空间，不一定可以长期保存）。

监视信息还必须包括来自系统其他部分的数据（如果适用）：例如，如果程序使用数据库，则包括来自数据库计算机的系统统计信息以及来自计算机的任何诊断输出。

数据库（包括性能报告，例如Oracle的自动工作负载仓库[AWR]报告）。

[该数据将指导对未发现的任何回归的分析。如果CPU使用率增加了，那么现在该查询配置文件信息以了解花费更多时间了。如果花费在GC上的时间增加了，就该查询一下堆配置文件以查看消耗更多内存的内容。如果CPU时间和GC时间减少，那么某个地方的争用可能会降低性能：堆栈数据可能指向特定的同步瓶颈（请参阅](part242.htm#bookmark636)[第](part242.htm#bookmark636)9[章](part242.htm#bookmark636)），JFR记录可用于查找应用程序延迟，或者数据库日志可以指向具有数据库争用增加。

[确定回归的来源时，是时候扮演侦探了，并且可用的数据越多，就会发现更多的线索。正如所讨论的](part23.htm#bookmark21)[第](part23.htm#bookmark21)1 ，它不一定的情况下，该JVM是回归。在任何地方进行一切测量，以确保可以进行正确的分析。

在目标系统上运行

在单核便携式计算机上运行的测试的行为与在具有256线程SPARC CPU的计算机上运行的测试的行为会有很大不同。就线程效果而言，这应该很清楚：大型计算机将同时运行更多线程，从而减少了应用程序线程之间对CPU的争用。同时，大型系统将显示小型笔记本电脑中未注意到的同步瓶颈。

即使没有那么明显的表现，其他性能差异也同样重要。许多重要的调优标志都基于运行JVM的基础硬件来计算其缺省值。各个平台的代码不同。缓存（软件，更重要的是硬件）在不同的系统上和不同的负载下具有不同的表现。等等…

因此，如果不测试预期硬件上的预期负载，就永远无法完全了解特定生产环境的性能。可以通过在较小的硬件上运行较小的测试来进行近似和推断，而在现实世界中，复制用于测试的生产环境可能非常困难或昂贵。但是外推仅仅是预测，即使在最好的情况下，预测也可能是错误的。大型系统不仅仅是其各个部分的总和，并且不能替代在目标平台上执行适当的负载测试。

快速总结

1.频繁的性能测试很重要，但这并不是在真空中进行的；在正常的开发周期中需要权衡取舍。

2.一个从所有机器和程序收集所有可能统计信息的自动化测试系统将为性能下降提供必要的线索。快速总结

1.正确确定两个测试的结果是否不同需要进行统计分析，以确保感知到的差异不是随机机会的结果。

2.严格的方法是使用学生的t检验比较结果。

3.来自t检验的数据告诉我们存在回归的可能性，但没有告诉我们应该忽略哪些回归，必须进行回归。找到平衡是性能工程的一部分。



1.频繁的性能测试很重要，但这并不是在真空中进行的；在正常的开发周期中需要权衡取舍。

2.一个从所有机器和程序收集所有可能统计信息的自动化测试系统将为性能下降提供必要的线索。

### （Operating System Tools and Analysis‌）操作系统工具与分析

程序分析的起点实际上根本不是特定于Java的：它是操作系统随附的基本监视工具集。在基于Unix的系统上，它们是sar（系统会计报告）及其组成工具，如vmstat，iostat，prstat等等。在Windows上，有图形资源监视器以及诸如typeperf之类的命令行实用程序。‌

每当运行性能测试时，都应从操作系统中收集数据。至少应收集有关CPU，内存和磁盘使用情况的信息。如果程序使用网络，则还应收集有关网络使用情况的信息。如果性能测试是自动化的，则意味着要依靠命令行工具（甚至在Windows上），但是即使测试以交互方式运行，最好还是使用

捕获输出的命令行工具，而不是盯着GUI图形并猜测其含义。以后进行分析时，始终可以将输出图形化。

CPU使用率

首先让我们看一下监视CPU及其对Java程序的影响。CPU使用率通常分为两类：用户时间和系统时间（Windows将其称为特权时间）。用户时间是CPU执行应用程序代码的时间百分比，而系统时间是CPU执行内核代码的时间百分比。系统时间与应用程序有关；例如，如果应用程序执行I / O，内核将执行代码以从磁盘读取文件，或将缓冲的数据写入网络，依此类推。任何使用基础系统资源的内容都将导致应用程序使用更多的系统时间。

性能的目标是在尽可能短的时间内使CPU使用率尽可能高。这听起来有点违反直觉。您毫无疑问地坐在您的桌面上，看着它挣扎，因为CPU被100％地使用了。因此，让我们考虑一下CPU使用率的实际情况。

首先要记住的是，CPU使用率是某个时间间隔内的平均值-5秒，30秒，甚至可能短至1秒（尽管从不真正少于此）。假设程序执行10分钟的平均CPU使用率为50％。如果对代码进行了调整，以使CPU使用率达到100％，则该程序的性能将提高一倍：它将在5分钟内运行。如果性能再次提高一倍，则在程序完成的2.5分钟内，CPU仍将保持100％的速度。CPU编号表示程序使用CPU的效率，因此编号越高越好。

如果在Linux桌面上运行vmstat 1，我将得到一系列如下所示的行（每秒一次）：

％**vmstat 1**

procs -----------内存---------- --- swap-- ----- io ---- -system-- ---- cpu-- -

rb swpd free buff cache si so bi bo in CS us sy id wa

| 2    | 0    | 0 1797836 1229068 1508276 0 | 0    | 0    | 9 2250 3634 41  | 3 55 | 0    |
| ---- | ---- | --------------------------- | ---- | ---- | --------------- | ---- | ---- |
| 2    | 0    | 0 1801772 1229076 1508284 0 | 0    | 0    | 8 2304 3683 43  | 3 54 | 0    |
| 1个  | 0    | 0 1813552 1229084 1508284 0 | 0    | 3    | 22 2354 3896 42 | 3 55 | 0    |
| 1个  | 0    | 0 1819628 1229092 1508292 0 | 0    | 0    | 84 2418 3998 43 | 2 55 | 0    |

本示例来自使用一个活动线程运行应用程序的情况，这使该示例更易于理解，但是即使存在多个线程，这些概念也适用。

在每秒中，CPU繁忙450毫秒（执行用户代码的时间占42％，执行系统代码的时间占3％）。同样，CPU空闲550毫秒。由于多种原因，CPU可能处于空闲状态：

•应用程序可能在同步原语上被阻止，并且在释放该锁之前无法执行。

•应用程序可能正在等待某些东西，例如从对数据库的调用返回的响应。

•应用程序可能无关。

前两种情况始终表明可以解决的问题。如果可以减少锁上的争用，或者可以调整数据库以使其更快地将答案发送回去，则程序将运行得更快，并且应用程序的平均CPU使用率将上升（当然，假设存在是不会继续阻止应用程序的另一个此类问题）。

第三点是混乱常常所在。如果应用程序有事要做（并且由于正在等待锁或其他资源而没有被阻止这样做），则CPU将花费周期来执行应用程序代码。这是一个通用原则，并不特定于Java。假设您编写了一个包含无限循环的简单脚本。执行该脚本时，它将消耗100％的CPU。以下批处理作业将在Windows中完成：

ECHO OFF

:BEGIN

ECHO LOOPING GOTO BEGIN

REM We never get here... ECHO DONE

考虑一下如果此脚本不占用100％的CPU意味着什么。这意味着操作系统可以执行某些操作-可以打印另一行显示LOOPING（循环） -但它选择空闲。在这种情况下，保持空闲状态对任何人都无济于事，如果我们进行了有用的（冗长的）计算，则强制CPU周期性地处于空闲状态将意味着要花更长的时间才能得到我们想要的答案。

如果您在单CPU计算机上运行此命令，则大多数时候您不太可能会注意到它正在运行。但是，如果您尝试启动一个新程序或调整另一个应用程序的性能，那么您肯定会看到效果。操作系统擅长在时间划分上争夺CPU周期的程序，但是新程序可使用的CPU更少，并且运行速度会更慢。这种经验有时使人们认为，留下一些空闲的CPU周期是个好主意，以防万一其他事情需要它们。

但是操作系统无法猜测您下一步要做什么。它（默认情况下）将执行所有可能的操作，而不是使CPU处于空闲状态。

限制程序的CPU

只要有可用的CPU周期，就运行程序可以最大化该程序的性能。有时您可能不希望这种行为。例如，如果运行*SETI @ home*，它将消耗计算机上所有可用的CPU周期。当您不工作时，或者只是在网上冲浪或编写文档时，这可能会很好，但否则可能会影响您的工作效率。（并且，我们不要考虑如果您正在玩CPU密集型游戏，会发生什么！）

许多特定于操作系统的机制可以人为地限制程序使用的CPU数量，实际上是迫使CPU离开空闲周期，以防万一某些人想要利用它们。也可以更改进程的优先级，以使这些后台作业不会占用您要运行的CPU，但仍不会留下空闲的CPU周期。这些技术超出了我们的讨论范围（根据记录，*SETI @ home*将允许您配置这些技术；除非您告知这样做，否则它实际上不会占用计算机上的所有备用周期）。

### Java和单CPU使用率

回到Java应用程序的讨论中，在这种情况下，周期性的空闲CPU是什么意思？这取决于应用程序的类型。如果所讨论的代码是具有固定工作量的批处理式应用程序，则您永远都不会看到空闲的CPU，因为没有工作要做。提高CPU使用率始终是批处理作业的目标，因为这意味着作业将更快地完成。如果CPU已经处于100％的状态，那么您当然仍然可以寻找优化方法，以使工作更快地完成（同时尝试将CPU保持在100％的状态）。

如果测量涉及服务器样式的应用程序，该应用程序接受来自某个源的请求，则可能存在空闲时间，因为没有可用的工作：例如，当Web服务器已处理所有未完成的HTTP请求并正在等待下一个请求时。这是平均时间的来源。vmstat示例输出是在执行应用程序服务器时执行的，该服务器每秒接收一个请求。应用服务器需要450毫秒来处理该请求，这意味着CPU实际上在450毫秒内100％繁忙，而在550毫秒内0％繁忙。据报道，这是因为CPU忙于45％。

尽管通常发生的粒度级别太小而无法可视化，但是运行基于负载的应用程序时，CPU的预期行为是像这样短暂地运行。如果CPU每半秒收到一个请求，并且处理请求的平均时间为225 ms，则从报告中可以看到相同的宏模式。CPU的繁忙时间为225 ms，空闲状态为275 ms，再次繁忙状态为225 ms，空闲状态为275 ms：平均而言，繁忙状态为45％，空闲状态为55％。

如果对应用程序进行了优化，以使每个请求仅花费400毫秒，那么总体CPU使用率也将降低（降至40％）。这是唯一有必要降低CPU使用率的情况-当有固定量的负载进入系统并且应用程序不受外部资源的约束时。另一方面，该优化还使您有机会向系统中添加更多负载，最终提高了CPU利用率。从微观上讲，这种情况下的优化仍然是在短时间内（执行请求需要400毫秒）将CPU使用率提高到100％的问题–只是CPU峰值的持续时间是太短，无法使用大多数工具有效地注册为100％。

##### Java和多CPU使用情况

[此示例假定了一个线程在单个CPU上运行，但是在多个线程在多个CPU上运行的一般情况下，这些概念是相同的。多个线程可能以有趣的方式扭曲CPU的平均值-](part127.htm#bookmark329)第5章中显示了[一个这样的示例](part127.htm#bookmark329)，其中显示了多个GC线程对CPU使用率的影响。但是总的来说，多CPU计算机上的多个线程的目标仍然是通过确保各个线程没有被阻塞来提高CPU的运行速度，或者由于线程已经完成工作而降低CPU的运行时间（长时间间隔）。并等待更多的工作。

在多线程，多CPU的情况下，还有关于CPU何时空闲的一个重要补充：即使有工作要做，CPU也会空闲。如果程序中没有可用的线程来处理该工作，则会发生这种情况。这里的典型情况是具有固定大小的线程池的应用程序正在运行各种任务。每个线程一次只能执行一个任务，并且如果该特定任务阻塞（例如，正在等待数据库的响应），则该线程将无法拾取新任务同时执行。因此，有时会存在要执行的任务（要完成的工作），但是没有线程可用于执行它们；结果是一些空闲的CPU时间。

[在该示例中，应增加线程池的大小。但是，不要仅仅因为空闲的CPU可用就意味着要增加线程池的大小才能完成更多工作。由于前面提到的另外两个原因，该程序可能没有获得CPU周期-由于锁或外部资源的瓶颈。在确定操作步骤之前，了解为什么程序没有获得CPU至关重要。（有关](part242.htm#bookmark636)此主题的更多详细信息，[请参见](part242.htm#bookmark636)[第9章](part242.htm#bookmark636) 。）

查看CPU使用率是了解应用程序性能的第一步，但这仅是：使用它来查看代码是否正在使用所有预期的CPU，或者它是否指向某些同步或资源问题。

#####  该CPU运行队列

Windows和Unix系统都允许您监视可以运行的线程数（这意味着它们不会在I / O或睡眠中被阻塞）。Unix系统

将其称为*运行队列*，并且一些工具在其输出中包括运行队列长度。这包括最后一部分中的vmstat输出：每行中的第一个数字是运行队列的长度。Windows将此数字称为*处理器队列*，并通过typeperf报告（其他方式）：

C：> **typeperf -si 1“ \ System \ Processor Queue Length”**

“ 05/11/2013 19：09：42.678”，“ 0.000000”

“ 05/11/2013 19：09：43.678”，“ 0.000000”

此处的输出有一个非常重要的区别：Unix系统上的运行队列长度数字（在示例vmstat输出中为1或2 ）是*正在*运行或*可以运行*的所有线程数（如果有可用的CPU。在该示例中，总是至少有一个线程要运行：执行应用程序工作的单个线程。因此，运行队列长度始终至少为1。请记住，运行队列代表了计算机上的所有内容，因此有时要运行其他线程（来自完全独立的进程），这就是为什么运行队列长度有时在该样本输出中为2。

在Windows中，处理器队列长度不包括当前正在运行的线程数。因此，在typeperf示例输出中，即使机器运行相同的单线程应用程序并始终执行一个线程，处理器队列号仍为0。

如果要运行的线程多于可用CPU，则性能将开始下降。因此，通常，您希望处理器队列长度在Windows上为0，并且等于（或小于）Unix系统上的CPU数量。这不是一个硬性规定。有一些系统流程和其他事物会定期出现，并短暂地提高该值，而不会对性能造成任何重大影响。但是，如果运行队列长度在相当长的一段时间内过长，则表明机器过载，您应该考虑减少机器正在做的工作量（通过将作业移至另一台机器或优化码）。

##### 快速总结

1.查看应用程序性能时，首先要检查CPU时间。

2.优化代码的目标是提高CPU使用率（在较短的时间内），而不是降低CPU使用率。

3.了解并尝试调试应用程序之前，为什么CPU使用率较低。

### 磁盘使用情况

监视磁盘使用情况有两个重要目标。其中第一个问题与应用程序本身有关：如果应用程序正在执行大量磁盘I/O，则该I/O很容易成为瓶颈。

[知道磁盘I/O何时成为瓶颈非常棘手，因为它取决于应用程序的行为。如果应用程序没有有效地缓冲它写入磁盘的数据（](part351.htm#bookmark914)第12章中[的示例](part351.htm#bookmark914)），则磁盘I/O统计信息将非常低。但是，如果应用程序执行的I/O数量超出磁盘处理能力，则磁盘I/O统计信息将非常高。无论哪种情况，性能都可以提高；都在寻找两者。

某些系统上的基本I / O监视器要好于其他系统。这是Linux系统上iostat的部分输出：

% **iostat -xm 5**

| avg-cpu: %user | %nice %system %iowait %steal              | %idle  |      |       |       |
| -------------- | ----------------------------------------- | ------ | ---- | ----- | ----- |
| 23.45          | 0.00           37.89     0.10        0.00 | 38.56  |      |       |       |
| Device:        | rrqm/s                                    | wrqm/s | r/s  | w/s   | rMB/s |
| sda            | 0.00                                      | 11.60  | 0.60 | 24.20 | 0.02  |



wMB/s avgrq-sz    avgqu-sz  await    r_await  w_await  svctm %util 

0.14       13.35        0.15           6.06     5.33        6.08        0.42     1.04

此处的应用程序正在将数据写入磁盘sda。乍一看，磁盘统计信息看起来不错。所述w_await -the时间服务中的每个I / O写是相当低的（6.08毫秒），并且该盘是利用仅1.04％。（可接受的值取决于物理磁盘，但是当服务时间低于15毫秒时，我的台式机系统中的5200 RPM磁盘性能良好。）但是这里有一个线索可能是错误的：系统正在花费37.89％在内核中的时间。如果系统正在执行其他I / O（在其他程序中），那是一回事。如果所有系统时间都来自被测试的应用程序，则说明效率低下。

系统每秒执行24.2次写入的事实是这里的另一个线索：当每秒仅写入0.14 MB（MBps）时，这是很多事情。I / O已成为瓶颈，下一步将是研究应用程序如何执行其写操作。

如果磁盘无法满足I / O请求，硬币的另一面也会出现：

**iostat -xm** **5**

| avg-cpu：％user | ％nice％system％iowait％steal | ％闲     |       |        |         |
| --------------- | ----------------------------- | -------- | ----- | ------ | ------- |
| 35.05           | 0.00 7.85 47.89 0.00          | 9.20     |       |        |         |
| 设备：          | rrqm /秒                      | wrqm /秒 | r /秒 | w / s  | rMB /秒 |
| sda             | 0.00                          | 0.20     | 1.00  | 163.40 | 0.00    |



wMB / s avgrq-sz avgqu-sz await r_await w_await svctm％util 

81.09 1010.19 142.74 866.47 97.60 871.17 6.08 100.00



关于Linux的好处是，它立即告诉我们磁盘已被100％使用。它还告诉我们，进程在iowait中花费了47.89％的时间（即等待磁盘）。

即使在只有原始数据可用的其他系统上，该数据也会告诉我们一些错误：完成I / O的时间（w_await）为871 ms，队列大小非常大，并且磁盘正在写入81 MB的数据。每秒数据。所有这些都表明磁盘I / O是一个问题，因此必须减少应用程序（或可能在系统中的其他位置）中的I / O数量。

监视磁盘使用情况的第二个原因（即使不期望应用程序执行大量的I/O）也是为了帮助监视系统是否正在交换。计算机具有固定的物理内存量，但是它们可以运行使用大量虚拟内存的一组应用程序。应用程序倾向于保留超出其实际需要的内存，并且它们通常仅在其一部分内存上运行。在这两种情况下，操作系统都可以将未使用的内存部分保留在磁盘上，并仅在需要时才将其分页到物理内存中。

[在大多数情况下，这种内存管理效果很好，特别是对于交互程序和GUI程序（这很好，否则您的笔记本电脑将需要的内存要多于它的内存）。它不适用于基于服务器的应用程序，因为这些应用程序倾向于使用更多的内存。而且由于Java堆，它对于任何类型的Java应用程序（包括在桌面上运行的基于Swing的GUI应用程序）尤其不利。有关此内容的更多详细信息，请参见](part127.htm#bookmark329)第5章。

进行交换的系统（将数据页从主内存移动到磁盘，反之亦然）通常将导致性能下降。其他系统工具也可以报告系统是否正在交换。例如，vmstat输出有两列（si，用于换入，so，用于换出），如果系统正在交换，它们会提醒我们。磁盘活动是另一个可能发生交换的指示。

快速总结

1.监视磁盘使用情况对于所有应用程序都很重要。对于不直接写入磁盘的应用程序，系统交换仍会影响其性能。

2.写入磁盘的应用程序可能会成为瓶颈，这是因为它们写入数据的效率低下（吞吐量太低）或因为写入了太多数据（吞吐量太高）。

### 网络使用

如果您正在运行使用网络的应用程序（例如，Java EE应用程序服务器），那么您还必须监视网络流量。网络使用情况为与磁盘流量类似：应用程序可能无法充分利用网络，从而导致带宽太低，或者写入特定网络接口的数据总量可能超出了接口的处理能力。

不幸的是，标准系统工具对于监视网络流量并不是很理想，因为它们通常仅显示通过特定网络接口发送和接收的数据包数量和字节数量。这是有用的信息，但是并不能告诉我们网络使用不足还是过度使用。

在Unix系统上，基本的网络监视工具是netstat（在大多数Linux发行版中，甚至不包括netstat，必须单独获得）。在Windows上，可以在脚本中使用typeperf来监视网络使用情况-但是在这种情况下，GUI具有优势：标准Windows资源监视器将显示一个图表，显示正在使用的网络百分比。不幸的是，GUI在自动化性能测试方案中几乎没有帮助。‌

[幸运的是，有许多开源工具和商业工具可以监视网络带宽。在Unix系统上，一个流行的命令行工具是](http://sourceforge.net/projects/nicstat)nicstat，它提供每个接口上流量的摘要，包括使用该接口的程度：

**nicstat  **5

| 时间     | 整数    | rKB /秒 | wKB /秒 | 千帕/秒 | 功率/秒 | 装甲车 | wAvs％Util星期六 |
| -------- | ------- | ------- | ------- | ------- | ------- | ------ | ---------------- |
| 17:05:17 | e1000g1 | 225.7   | 176.2   | 905.0   | 922.5   | 255.4  | 195.6 0.33 0.00  |

% **nicstat 5**

| Time     | Int     | rKB/s | wKB/s | rPk/s | wPk/s | rAvs  | wAvs %Util Sat  |
| -------- | ------- | ----- | ----- | ----- | ----- | ----- | --------------- |
| 17:05:17 | e1000g1 | 225.7 | 176.2 | 905.0 | 922.5 | 255.4 | 195.6 0.33 0.00 |

e1000g1接口是1000 MB接口; 在此示例中，利用率不高（0.33％）。该工具（和其他类似工具）的用处在于它可以计算接口的利用率。在此输出中，通过接口写入225.7 Kbps的数据，并读取176.2 Kbps的数据。对1,000 MB的网络进行分割，得出的利用率为0.33％，nicstat工具可以自动确定接口的带宽。

typeperf或netstat之类的工具将报告读取和写入的数据量，但是要弄清网络利用率，必须确定接口的带宽并在自己的脚本中执行计算。请记住，尽管工具通常报告每秒字节数（Bps），但带宽以每秒比特数（bps）为单位。一个1,000兆位的网络每秒产生125兆字节（MB）。在此示例中，读取了0.22 MBps，写入了0.16 MBps。将这些值相加并除以125可得出0.33％的利用率。因此，nicstat（或类似工具）没有神奇之处。他们只是更方便使用。

网络无法维持100％的利用率。对于局域以太网，持续利用率超过40％表示接口已饱和。如果网络是分组交换的或使用不同的介质，则最大可能的持续速率将有所不同。咨询网络架构师以确定适当的目标。这个目标是独立于Java的，Java将仅使用操作系统的网络参数和接口。

快速总结

1.对于基于网络的应用程序，请确保监视网络以确保它没有成为瓶颈。

2.写入网络的应用程序可能会成为瓶颈，因为它们写入数据的效率低下（吞吐量太低）或写入数据太多（吞吐量太高）。

### Java Monitoring Tools(Java监视工具)

为了深入了解JVM本身，需要Java监视工具。JDK附带了许多工具：

jcmd

打印Java进程的基本类，线程和VM信息。这适合在脚本中使用；它是这样执行的：

**jcmd process_id command optional_arguments**

提供命令帮助将列出所有可能的命令，并提供帮助

<command>将给出特定命令的语法。

jconsole

提供JVM活动的图形视图，包括线程使用，类使用和GC活动。

jhat

读取并帮助分析内存堆转储。这是一个后处理实用程序。

jmap

提供堆转储和有关JVM内存使用的其他信息。尽管必须在后处理工具中使用堆转储，但适用于脚本编写。

jinfo

提供对JVM的系统属性的可见性，并允许动态设置某些系统属性。适合脚本编写。

jstack

转储Java进程的堆栈。适合脚本编写。

jstat

提供有关GC和类加载活动的信息。适合脚本编写。

jvisualvm

一个GUI工具，用于监视JVM，分析正在运行的应用程序并分析JVM堆转储（这是一种后处理活动，尽管jvisualvm也可以从活动程序中获取堆转储）。

这些工具适合以下广泛领域：

•虚拟机基本信息 Basic VM information

•线程信息 Thread information

•班级信息 Class information

•实时GC分析 Live GC analysis

•堆转储后处理 Heap dump postprocessing

•分析JVM  Profiling a JVM

你可能注意到了，这里没有一对一的映射;许多工具在多个领域执行功能。因此，我们不是单独研究每个工具，而是研究对Java很重要的可见性功能领域，并讨论各种工具是如何提供这些信息的。在此过程中，我们将讨论其他工具(一些开源的，一些商业的)，它们提供相同的基本功能，但比基本JDK工具有优势。

##### Basic VM Information‌

JVM工具可以提供关于运行中的JVM进程的基本信息:它运行了多长时间、使用了什么JVM标志、JVM系统属性，等等。

###### Uptime

The length of time the JVM has been up can be found via this command:

JVM运行的时间长度可以通过下面的命令来查找:

% **jcmd process_id VM.uptime**

###### System properties

getproperties()中的项集可以用以下命令中的任意一条来显示:

% **jcmd process_id VM.system_properties**

or

% **jinfo -sysprops process_id**

这包括命令行上用-D选项设置的所有属性、应用程序动态添加的所有属性以及JVM的一组默认属性。

###### JVM version

JVM的版本是这样获得的:

% **jcmd process_id VM.version**

JVM command line

命令行可以显示在jconsole或via的VM摘要选项卡中jcmd:

% **jcmd process_id VM.command_line**

JVM tuning flags

应用程序的有效调优标志可以这样获得:

% **jcmd process_id VM.flags [-all]**

### 使用调整标志

JVM可以使用许多调优标志，其中许多标志是本书的主要重点。跟踪这些标志及其默认值可能有点困难;在这方面，jcmd的最后两个示例非常有用。command_line命令显示在命令行上直接指定的标志。flags命令显示了在命令行上设置了哪些标志，以及一些由JVM直接设置的标志(因为它们的值是间接确定的)。包括-all选项将列出JVM中的每个标志。

[数百个JVM调优标志，其中大多数都很模糊。建议不要更改其中的大多数（请参见](part66.htm#bookmark178)[第](part66.htm#bookmark178)49[页的“信息太多？”](part66.htm#bookmark178)）。诊断性能问题时，经常要弄清哪些标志有效，而jcmd命令可以针对正在运行的JVM执行此操作。通常，您更希望弄清特定JVM的特定于平台的默认值，在这种情况下，在命令行上使用-XX：+ PrintFlagsFinal选项会更加有用。

确定在特定平台上设置标志的有用方法是执行以下命令：

％**java other_options -XX：+ PrintFlagsFinal -version**

...数百行输出，包括...

uintx InitialHeapSize：= 4169431040 {product}

intx InlineSmallCode = 2000 {pd product}

您应该在命令行上包括所有其他选项，因为某些选项会影响其他选项，尤其是在设置与GC相关的标志时。这将打印出JVM标志及其值的完整列表（与通过JVM的jcmd的VM.flags -all选项打印的结果相同）。

这些命令的标志数据以所示两种方式之一打印。包含的输出的第一行中的冒号表示该标志正在使用非默认值。发生这种情况的原因如下：

1.标志的值直接在命令行上指定。

2.其他一些选项间接更改了该选项。

3. JVM按照人体工程学计算了默认值。

第二行（不带冒号）表示该值是此版本JVM的默认值。在不同的平台上，某些标志的默认值可能有所不同，这在此输出的最后一栏中显示。product表示该标志的默认设置在所有平台上都是统一的；pd product表示该标志的默认设置取决于平台。



### 过多的信息？

该PrintFlagsFinal命令将打印出数百个可用的调优标志JVM的（有可能的668个旗帜在JDK 7u40，例如）。

这些标志中的绝大多数旨在使支持工程师能够从正在运行（和行为异常）的应用程序中收集更多信息。令人着迷的是，有一个名为AllocatePrefetchLines的标志（默认值为3）来假定可以更改该值，以便在特定处理器上执行指令预取可能会更好。但是，这种偶然的调整在真空中不值得。在没有充分理由的情况下，不应更改这些标志。在使用AllocatePrefetchLines标志的情况下，这包括对应用程序的预取性能的了解，运行应用程序的CPU的特性以及更改数字对JVM代码本身的影响。



最后一列的其他可能值包括可管理的（该标志的值可以在运行时动态更改）和C2诊断（该标志提供诊断输出，以使编译器工程师了解编译器的工作方式）。

查看正在运行的应用程序的此信息的另一种方法是使用jinfo。jinfo的优点是它允许在程序执行期间更改某些标志值。

这是如何检索过程中所有标志的值：

**jinfo -flags process_id**

使用-flags选项，jinfo将提供有关所有标志的信息；否则，它仅打印在命令行上指定的内容。这两个命令的输出都不像-XX：+ PrintFlagsFinal选项那样容易读取，但是jinfo需要牢记其他功能。

jinfo可以检查单个标志的值：

**jinfo -flag PrintGCDetails process_id**

-XX：+ PrintGC详细信息

尽管jinfo本身并不指示标志是否可管理，但是可以通过jinfo打开或关闭可管理的标志（在使用PrintFlagsFinal参数时标识）：

％**jinfo -flag -PrintGCDetails process_id**＃关闭PrintGCDetails

％**jinfo -flag PrintGCDetails process_id**

-XX:+PrintGCDetails

请注意，jinfo可以更改任何标志的值，但这并不意味着JVM将响应该更改。例如，大多数影响GC算法行为的标志都在启动时用于确定收集器的行为方式。稍后通过jinfo更改标志不会导致JVM更改其行为。它将根据算法的初始化方式继续执行。因此，该技术仅适用于在PrintFlagsFinal命令的输出中标记为可管理的那些标志。

快速总结

1. jcmd可用于查找正在运行的应用程序的基本JVM信息（包括所有调整标志的值）。

2.通过在命令行中包含-XX：+ PrintFlags Final，可以找到默认标志值。这对于确定特定平台上标志的默认人体工程学设置很有用。

3. jinfo对于检查（在某些情况下会更改）单个标志很有用。



### 线程信息 Thread Information

jconsole和jvisualvm实时显示有关应用程序中运行的线程数的信息。

查看正在运行的线程堆栈以确定它们是否被阻塞可能非常有用。可以通过jstack获得堆栈：

％**jstack process_id**

...大量输出显示每个线程的堆栈...

栈信息也可以从jcmd获得：

％**jcmd process_id Thread.print**

...大量输出显示每个线程的堆栈...

[有关](part242.htm#bookmark636)监视线程堆栈的更多详细信息，[请参见](part242.htm#bookmark636)第9章。

### 类信息 class information

可以从以下位置获取有关应用程序正在使用的类数的信息：

jconsole或jstat 。jstat还可以提供有关类编译的信息。

[有关](part351.htm#bookmark914)[应用程序使用类的更多详细信息，](part92.htm#bookmark248)[请参见](part351.htm#bookmark914)第12章，有关监视类编译的详细信息，[请参见](part351.htm#bookmark914)第4章。

### Live GC Analysis

几乎每个监控工具都会报告有关GC活动的信息。jconsole显示堆使用情况的实时图表；jcmd允许执行GC操作；jmap可以在永久代上打印堆摘要或信息，也可以创建堆转储；而jstat对垃圾收集器的工作产生了许多不同的看法。[有关](part127.htm#bookmark329)这些程序如何监视GC活动的示例，[请参见](part127.htm#bookmark329)第5章。

### 堆转储后处理 Heap Dump Postprocessing

可以从jvisualvm GUI或使用jcmd或jmap从命令行捕获堆转储。堆转储是堆的快照，可以使用各种工具（包括jvisualvm和jhat）对其进行分析[。堆转储处理是传统上第三方工具比JDK领先的一个领域，因此](part191.htm#bookmark481)[第](part191.htm#bookmark481)7[章](part191.htm#bookmark481)使用第三方工具Eclipse Memory Analyzer Tool来提供有关如何对堆进行后处理的示例。转储。

### 分析工具Profiling Tools

探查器Profilers是性能分析师工具箱中最重要的工具。有许多可用于Java的探查器，每个探查器都有自己的优点和缺点。剖析是通常使用不同工具的一个领域，尤其是当它们是采样探查器时。一个采样分析器可能会发现与另一个问题不同的问题，即使在同一应用程序上也是如此。

几乎所有的Java性能分析工具本身都是用Java编写的，并且通过将自身“附加”到要进行概要分析的应用程序来工作，这意味着概要分析器为目标应用程序打开了套接字（或其他通信通道）。然后，目标应用程序和配置工具交换有关目标应用程序行为的信息。

这意味着您必须注意调整配置工具，就像调整任何其他Java应用程序一样。特别是，如果正在分析的应用程序很大，它将把大量数据传输到性能分析工具，因此性能分析工具必须有足够大的堆来处理数据。通常，使用

并发GC算法；在分析工具中，由于时间不正确的完整GC暂停会导致保存数据的缓冲区溢出。

### 采样探查器Sampling Profilers

分析以两种模式之一进行：采样模式或检测模式。采样模式是配置的基本模式，并且开销最少。这很重要，因为剖析的陷阱之一是通过将度量引入应用程序，您正在改变其性能特征。（仍然，您必须进行剖析：程序内的猫是否还活着，您还会如何知道？）限制分析的影响将导致结果更精确地模拟应用程序在通常情况下的行为。

不幸的是，采样分析器可能会遭受各种错误。当计时器定期触发时，采样分析器开始工作。然后，探查器查看每个线程并确定该线程正在执行哪种方法。自从计时器被触发以来，该方法就被执行了。

图3-1[说明了最常见的采样误差](part73.htm#bookmark192)。这里线程是执行之间alter-内廷了methodA和（在阴影条示出）的methodB（在清晰条示出）。如果计时器仅在线程恰好在methodB中时才触发，则配置文件将报告该线程花费了全部时间执行methodB ; 在现实中，更多的时间是实际支出了methodA。

![图片](E:\learningforalllife\git-workspace\PANDA-Walker\picture\Image_045.png)

图3-1。备用方法执行

这是最常见的采样误差，但绝不是唯一的误差。最小化这些误差的方法是在更长的时间内进行剖析，并减少样本之间的时间间隔。减小样本之间的间隔与将分析对应用程序的影响最小化的目标相反。这里有一个平衡。概要分析工具以不同的方式解决了这种平衡，这就是为什么一个概要分析工具可能会报告与另一种工具不同的数据的原因之一。

图3-2显示了用来测量GlassFish应用服务器域启动的基本采样配置文件。该配置文件显示，大部分时间（19％）花费在defineClass1（）方法上，其次是getPackageSourcesInternal（）方法，等等。程序的启动将被定义类的性能所支配，这并不奇怪。为了使此代码更快，必须提高类加载的性能。

![图片](E:\learningforalllife\git-workspace\PANDA-Walker\picture\Image_046.png)

图3-2。基于样本的配置文件

请仔细注意最后一条语句：必须提高类加载的性能，而不是defineClass1（）方法的性能。查看概要文件时的常见假设是，必须通过优化概要文件中的顶部方法来进行改进。但是，这通常过于局限。在这种情况defineClass1（）方法是JDK的一部分，也是该方法的本机方法。如果不重写JVM，其性能将不会得到改善。尽管如此，请假设可以对其进行重写，从而节省了60％的时间。这将使执行时间总体上提高10％，这当然是不容小看的。

不过，更常见的是，配置文件中的顶部方法可能会花费总时间的3％中的2％；将其时间缩短一半（通常是非常困难的）只会将应用程序性能提高1％。仅关注配置文件中的顶部方法通常不会导致性能上的巨大提高。

相反，配置文件中最重要的方法应该将您指向要搜索优化的区域。GlassFish性能工程师不会尝试使类定义更快，但是他们可以弄清楚总体上如何加快类加载速度

-通过加载较少的类，并行加载类，等等。

快速总结

1.基于采样的探查器是最常见的探查器。

2.由于采样轮廓仪相对较低，因此引入的测量伪影更少。

3.不同的采样曲线表现不同。每个都可能适合特定的应用程序。

### Instrumented Profilers 仪表廓线仪

[仪器分析器比采样分析器更具侵入性，但是它们也可以提供有关程序内部正在发生的事情的更多有用信息。](part75.htm#bookmark196)[图3-3](part75.htm#bookmark196) 使用相同的配置工具来查看同一GlassFish域的启动，但是这次它是使用检测模式。

![图片](E:\learningforalllife\git-workspace\PANDA-Walker\picture\Image_048.png)

图3-3。仪器配置文件

关于此配置文件的一些事情是显而易见的。首先，请注意，“热”方法现在是getPackageSourcesInternal（），占总时间的13％（而不是上一个示例中的4％）。在配置文件顶部附近还有其他昂贵的方法，而且defineClass1（）方法根本不会出现。该工具现在还报告每个方法被调用的次数，并基于该次数计算每次调用的平均时间。

这是比采样版本更好的配置文件吗？这取决于; 在给定的情况下，没有办法知道更准确的配置文件。仪器配置文件的调用计数当然是准确的，并且附加信息通常对于确定代码实际在哪里花费更多时间以及哪些事情进行优化更有帮助。在这种情况下，尽管ImmutableMap.get（）方法消耗了总时间的12％，但被称为470万次。通过减少对该方法的调用总数而不是加快其实现，可以对性能产生更大的影响。

[另一方面，有条件的探查器通过在加载类时更改类的字节码顺序来工作（插入代码以计算调用次数，依此类推）。与采样分析器相比，它们更有可能在应用程序中引入性能差异。例如，JVM将内联小的方法（请参见](part92.htm#bookmark248)第4章），以便在执行小方法代码时不需要方法调用。编译器根据代码的大小做出决定。根据代码的检测方式，可能不再适合于内联。这可能会导致仪器分析器高估了某些方法的贡献。内联只是编译器根据代码布局做出决定的一个示例；通常，对代码的检测（更改）越多，其执行配置文件更改的可能性就越大。

还有一个有趣的技术原因，即ImmutableMap.get（）方法显示在此配置文件而不是采样配置文件中。Java中的采样探查器仅在线程处于安全点时（实质上，无论何时分配内存）都可以获取线程的样本。该GET（）方法可能永远不会在一个还原点到达，所以可能永远不会采样。这意味着采样配置文件可能会低估该方法对程序执行的贡献。

在此示例中，检测和采样概要文件均指向代码的相同常规区域：类加载和类解析。实际上，不同的探查器可能指向完全不同的代码区域。探查器是很好的估计器，但它们只是在进行估计：其中一些有时会是错误的。

快速总结

1.仪器分析仪会提供有关某个应用程序的更多信息，但可能会比采样分析仪对应用程序产生更大的影响。

2.应该设置检测分析器以检测代码的一小部分-几个类或程序包。这限制了它们对应用程序性能的影响。

### Blocking Methods and Thread Timelines阻断方法和线程时间表

图3-4显示了使用其他检测的分析工具（NetBeans分析器）启动的GlassFish。现在，执行时间由park（）和parkNanos（）方法（在较小程度上是read（）方法）控制。

![image](E:\learningforalllife\git-workspace\PANDA-Walker\picture\Image_050.png)

图3-4。配置文件被阻止的方法 A profile with blocked methods

这些方法（和类似的阻塞方法）不会消耗CPU时间，因此它们不会对应用程序的总体CPU使用率产生影响。他们的处决不能必须进行优化。应用程序中的线程不会花费632秒的时间在parkNanos（）方法中执行代码。他们花费632秒等待其他事情发生（例如，另一个线程调用notify（）方法）。park（）和read（）方法也是如此。

因此，大多数分析器不会报告被阻止的方法。这些线程显示为空闲（在这种情况下，NetBeans被设置为显式包括那些线程和所有其他Java级方法）。在此特定示例中，这是一件好事：驻留的线程是Java线程池的线程，它们将在它们进入服务器时执行servlet（和其他）请求。启动期间不会发生此类请求，因此这些线程将保持阻塞状态，以等待某些任务执行。那是他们的正常状态。

在其他情况下，您确实希望查看这些阻止呼叫所花费的时间。线程在wait（）方法中花费的时间-等待其他线程通知它是许多应用程序总体执行时间的重要决定因素。大多数基于Java的探查器都具有过滤器集和其他选项，可以对其进行调整以显示或隐藏这些阻塞调用。

[或者，通常检查线程的执行模式比分析器将属性分配给阻塞方法本身的时间更有效。](part77.htm#bookmark200)图3-5显示了Oracle Solaris Studio分析工具中的此类线程显示。

![image](E:\learningforalllife\git-workspace\PANDA-Walker\picture\Image_051.png)

图3-5。线程时间线配置文件 A thread timeline profile

这里的每个水平区域都有一个不同的线程（因此图中有两个线程：线程1.3和线程1.2）。彩色（或不同的灰度）条表示执行不同的方法。空白区域表示线程未执行的位置。在较高的级别上，请注意线程1.2执行了大量代码，然后等待线程

1.3做某事；然后线程1.3等待一点时间让线程1.2做其他事情，依此类推。使用该工具深入这些领域，使我们能够了解这些线程之间如何相互作用。

还要注意，在空白区域中似乎没有线程正在执行。该图像仅显示应用程序中许多线程中的两个，因此这些线程有可能正在等待其他线程之一做某事，或者该线程可能正在执行阻塞的read（）（或类似）调用。

快速总结

1.被阻塞的线程可能会或可能不会成为性能问题的根源；有必要检查为什么它们被阻止。

2.阻塞的线程可以通过阻塞的方法或线程的时间线分析来识别。